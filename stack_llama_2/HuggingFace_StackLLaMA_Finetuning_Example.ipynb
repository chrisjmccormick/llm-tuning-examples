{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNs7p5STqUtgLjpsljvpbwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2619e4050ff415b8acda4f48feb8588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bd94337ce2c4e919d41c5e6263dfffa",
              "IPY_MODEL_d36236e8922e41318ede69b00141786c",
              "IPY_MODEL_38420a456340434db815d06ea47e0fc3"
            ],
            "layout": "IPY_MODEL_354ba73e572543a8a7a9a07a8f82da46"
          }
        },
        "5bd94337ce2c4e919d41c5e6263dfffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926e41df6ee54719992dc81a6796f40a",
            "placeholder": "​",
            "style": "IPY_MODEL_d991d44099a64628a7bfe9369f548946",
            "value": "Resolving data files: 100%"
          }
        },
        "d36236e8922e41318ede69b00141786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad819705af4458f9ca76e3595993e8f",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_750629903964429989e3a1e2d6610737",
            "value": 20
          }
        },
        "38420a456340434db815d06ea47e0fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b23a7a0bd149418c5871eb69df89f5",
            "placeholder": "​",
            "style": "IPY_MODEL_1bf1f6d34eec4c5196d4b91fc5c98ca6",
            "value": " 20/20 [00:00&lt;00:00,  1.45it/s]"
          }
        },
        "354ba73e572543a8a7a9a07a8f82da46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926e41df6ee54719992dc81a6796f40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d991d44099a64628a7bfe9369f548946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ad819705af4458f9ca76e3595993e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750629903964429989e3a1e2d6610737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6b23a7a0bd149418c5871eb69df89f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf1f6d34eec4c5196d4b91fc5c98ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a9619df1364fbe896e0678401866bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82593e74a87a4cf38d457dbf2cc182ab",
              "IPY_MODEL_2282cc32a4f04e60b4d541ca9357d0c0",
              "IPY_MODEL_838daf2bb0be44439c4020ab5c507321"
            ],
            "layout": "IPY_MODEL_72f6f1924ff54484b8681a3ecc2fe9cb"
          }
        },
        "82593e74a87a4cf38d457dbf2cc182ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cf30478e2446e0a62ee69f89820e5a",
            "placeholder": "​",
            "style": "IPY_MODEL_a7b3ed3e609a4fc68c470eef0415f872",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2282cc32a4f04e60b4d541ca9357d0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eef5d550d1b45a48073faceb9e5e79a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b534fa8f6d4f40ceac4d896f5b9240d8",
            "value": 2
          }
        },
        "838daf2bb0be44439c4020ab5c507321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f262ac1b5e7475c84c96ae2e69deab3",
            "placeholder": "​",
            "style": "IPY_MODEL_daa1730e4d5846f78daf56deed0018da",
            "value": " 2/2 [00:11&lt;00:00,  5.52s/it]"
          }
        },
        "72f6f1924ff54484b8681a3ecc2fe9cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34cf30478e2446e0a62ee69f89820e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b3ed3e609a4fc68c470eef0415f872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eef5d550d1b45a48073faceb9e5e79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b534fa8f6d4f40ceac4d896f5b9240d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f262ac1b5e7475c84c96ae2e69deab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa1730e4d5846f78daf56deed0018da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6ec086957ff45328eb686076e47d5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d4f8ae68bc8476b8dfdf4b83a45ac23",
              "IPY_MODEL_70cbb82869d44dc58b0123a61cb960dd",
              "IPY_MODEL_01fbfc1edf8445d0a7851e8a419b565e"
            ],
            "layout": "IPY_MODEL_8f79322547da4490af31b2ba72852a68"
          }
        },
        "6d4f8ae68bc8476b8dfdf4b83a45ac23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ed83db162e4ccd8f4b863177cc126b",
            "placeholder": "​",
            "style": "IPY_MODEL_57e5ed7f2d394e4fb27dbf65cfb50c1a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "70cbb82869d44dc58b0123a61cb960dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea2f81b0ab94b6cae640d2906282a5e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b86e70084864e228deb57e6c6ef3a7f",
            "value": 2
          }
        },
        "01fbfc1edf8445d0a7851e8a419b565e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1593c4f3b844c2a4bbb74a5d000386",
            "placeholder": "​",
            "style": "IPY_MODEL_eaae97d658974500a5d6df0e4578ac34",
            "value": " 2/2 [00:08&lt;00:00,  3.85s/it]"
          }
        },
        "8f79322547da4490af31b2ba72852a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ed83db162e4ccd8f4b863177cc126b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e5ed7f2d394e4fb27dbf65cfb50c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bea2f81b0ab94b6cae640d2906282a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b86e70084864e228deb57e6c6ef3a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b1593c4f3b844c2a4bbb74a5d000386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaae97d658974500a5d6df0e4578ac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisjmccormick/llm-tuning-examples/blob/main/stack_llama_2/HuggingFace_StackLLaMA_Finetuning_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ▂▂▂▂▂▂▂▂▂▂▂▂▂▂"
      ],
      "metadata": {
        "id": "PNz3loY3pnHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "DgCAwc5X3DbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.1. The StackLLaMa Example"
      ],
      "metadata": {
        "id": "tebRwiXULw84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace produced this example project to demonstrate their `trl` library (Transformer Reinforcement Learning).\n",
        "\n",
        "Using the Stack Exchange dataset (which provides roughly 30M examples of question and answer pairs), they demonstrate how to take a \"raw\" language model and take it through the same Supervised Fine-Tuning (SFT) + Reinforcement Learning (RL) training methodology that was used to turn GPT-3.5 into the much better-behaved ChatGPT.\n",
        "\n",
        "I believe the intent here is to train the model to be better at answering questions. 🤷‍♂️ There's more on the task itself down in the Dataset section of the Notebook.\n",
        "\n",
        "Their example is divided into two parts, one for the SFT step and the other for the RL step. Since my primary question here is \"is this doable on a single GPU?\", I wanted to start with just step 1 for now--the fine-tuning step.\n"
      ],
      "metadata": {
        "id": "0aqzi3Z7Qe9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.2. Mistral-7B"
      ],
      "metadata": {
        "id": "0oiK9nkt-VJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They used LLaMa from Facebook as their raw LLM starting point, and then dubbed the final trained model \"StackLLaMa\".\n",
        "\n",
        "The more recent Mistral 7B model claims superiority, seems to be very popular and, most importantly... doesn't require filling out a form to get access to the weights. 😅\n",
        "\n",
        "So I've swapped in Mistral 7B instead, and now I suppose we're building \"StackMistral\"!\n",
        "\n",
        "Here's a timeline of these different models and some relevant links for reference:\n",
        "\n",
        "* Feb 2023 - LLaMa 1\n",
        "* Jul 2023 - LLaMa 2\n",
        "* Sep 2023 - Mistral 7B ([post](https://mistral.ai/news/announcing-mistral-7b/), [model card](https://huggingface.co/mistralai/Mistral-7B-v0.1))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5S76X9kk-X01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## I.3. StackLLaMa v1 and v2\n"
      ],
      "metadata": {
        "id": "b_2Fq2B76fOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "They've published two versions of this example, and I'm going off of version 2 in this tutorial.\n",
        "\n",
        "The original author is Leandro Von Wera (who appears to be the maintainer of the `trl` library?)."
      ],
      "metadata": {
        "id": "BwkJeNFE-T_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Version 1**\n",
        "\n",
        "The [blog post](https://huggingface.co/blog/stackllama), published 4/5/23.\n",
        "\n",
        "\n",
        "\n",
        "The code (in script form) for the example is on GitHub under [examples/ research_projects/ stack_llama/ scripts/](https://github.com/huggingface/trl/tree/main/examples/research_projects/stack_llama/scripts/)\n",
        "\n",
        "The dataset they used in both examples is `stack-exchange-paired`, which you can view on huggingface datasets [here](https://huggingface.co/datasets/lvwerra/stack-exchange-paired).\n"
      ],
      "metadata": {
        "id": "_kxLZRQsArHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Version 2**\n",
        "\n",
        "They released a second version built on LLaMa 2, and demonstrated using the \"DPO\" method for the reinforcement learning part.\n",
        "\n",
        "They also tweaked a few other training settings for the SFT step, and we'll use those updated settings here.\n",
        "\n",
        "Their [blog post](https://huggingface.co/blog/dpo-trl), published 8/8/23.\n",
        "\n",
        "The code (in script form) is available on their GitHub under [examples/ research_projects/ stack_llama_2/ scripts/](https://github.com/huggingface/trl/tree/main/examples/research_projects/stack_llama_2/scripts)\n"
      ],
      "metadata": {
        "id": "S8Y_sMHXAsAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Trained Versions**\n",
        "\n",
        "In order to get your hands on LLaMa v1 or v2, you have to fill out a form to request it from Facebook 🙁 (which is why we'll be using Mistral-7B instead!).\n",
        "\n",
        "For StackLLaMa version 1, they didn't exactly publish the fully trained version, just the adapter weights that you can then apply to LLaMa v1.\n",
        "\n",
        "However, for version 2, they _did_ publish the full trained model (meaning you don't need to first acquire LLaMa 2 to download and try it out!).\n",
        "\n",
        "There's also a web app embedded in their StackLLaMa 2 [blog post](https://huggingface.co/blog/dpo-trl) that let's you quickly try it out!\n"
      ],
      "metadata": {
        "id": "7wGOLKOkAs90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**This Notebook**\n",
        "\n",
        "This Notebook is a (heavily modified 😝) version of the fine-tuning script, [supervised_finetuning.py](https://github.com/huggingface/trl/blob/main/examples/research_projects/stack_llama/scripts/supervised_finetuning.py).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D33vKZg7Au8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter Choices**\n",
        "\n",
        "| Settings                    | Version 1       | Version 2       |\n",
        "|-----------------------------|-----------------|-----------------|\n",
        "| Model                       | LLaMA 1 7B      | LLaMA 2 7B      |\n",
        "| Maximum Sequence Length     | 1024            | None            |\n",
        "| Effective Batch Size        | 4               | 8               |\n",
        "| Batch Size, Accumulation Steps | 4, 1         | 4, 2            |\n",
        "| Learning Rate               | 1e-5            | 1e-4            |\n",
        "| Steps                       | 5000            | 500             |\n",
        "| Optimizer                   | -               | paged_adamw_32bit |\n",
        "| Gradient Checkpointing      | False           | False           |\n",
        "| Lora ‘r’ and ‘alpha’        | r=16, alpha=32  | r=8, alpha=16   |\n",
        "| Quantization                | 8-bit           | 4-bit           |\n",
        "| BFloat16                    | False           | True            |\n",
        "\n",
        "A couple parameter choices aren't specified, and so must be using the default values. The documentation is hard to follow, but as best I can tell the default optimizer for the Trainer is AdamW, and setting the sequence length to 'None' causes it to retrieve that value from the tokenizer.\n"
      ],
      "metadata": {
        "id": "bPusDJCFmi3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.4. GPU Selection"
      ],
      "metadata": {
        "id": "rTo7RzDgf2dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll want to use different settings to run this Notebook on the **T4** (free) vs. the **L4** or **A100** (paid).\n",
        "\n",
        "(FYI, I went into depth on the available Colab GPUs and their features and pricing [here](https://mccormickml.com/2024/04/23/colab-gpus-features-and-pricing/)).\n",
        "\n",
        "Here are the ideal settings that will work for each GPU. This Notebook is currently configured with the settings required to run on the **T4**.\n",
        "\n",
        "|  GPU | dtype | Seq Len | Grad Check | Batch Size | Accumulation Steps | Memory Use |   Time   | Speed vs. T4 |\n",
        "|:----:|:----:|:-------:|:----------:|:----------:|:------------------:|:----------:|:------------------------------:|:------------:|\n",
        "|  **T4**  |   float16  |  1024  |    True    |      1     |          4         | 7.0GB      | ~2h 10min |      1x      |\n",
        "|  **L4**  |   bfloat16  |   1024  |    False   |      1     |          4         |  17.5GB    | ~47min      |     2.8x     |\n",
        "| **A100** |   bfloat16  |   1024  |    False   |      2     |          2         |   28.1 GB  | ~10min |      13x     |\n",
        "\n",
        "The last three columns (memory use, training time, and the speed comparison vs. the T4) are just for reference, but the other columns indicate specific settings to use.\n",
        "\n",
        "Note: One hack to get around a lot of the memory and performance issues would be to simply use a much smaller model. I've seen Facebook's `OPT-350m` used in some of HuggingFace's other examples.\n",
        "    * https://huggingface.co/facebook/opt-350m\n",
        "    * ~125k downloads last month\n",
        "    * Published 5/2/22 - 6/21/22\n",
        "\n",
        "**TODO**\n",
        "\n",
        "* In reporting the above times, I forgot about the validation step--it adds a lot to the total training time!\n",
        "* The examples validation set size of 4,000 isn't practical on the T4... I've reduced it to _50_ for now.\n",
        "* The v2 example actually uses an effective batch size of 8, so I need to up the accumulation steps!\n",
        "    * This may be **critical**, since the learning rate was tuned for that batch size.\n",
        "* I'll need to make it clear how users can change these settings in the notebook.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cdnEvJ6hf5N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ▂▂▂▂▂▂▂▂▂▂▂▂▂▂"
      ],
      "metadata": {
        "id": "LlSR8egkO9an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Code"
      ],
      "metadata": {
        "id": "TZYeiA4RO-NG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On to the example code!\n"
      ],
      "metadata": {
        "id": "k3D6WMEfuRvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**NOTE! API Keys Required**\n",
        "\n",
        "This Notebook currently requires both a huggingface API key (necessary for accessing mistral 7B) and wandb API key (optional--you could disable wandb in the training arguments). I made use of the 'secrets' panel in Colab to do this. You can do the same, or just paste your key directly into the code (in your own private copy of the Notebook).\n",
        "\n",
        "**TODO** - Provide some direction on how to do this!"
      ],
      "metadata": {
        "id": "ihGjgQWtvO-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S1. Setup"
      ],
      "metadata": {
        "id": "5SQG_3LBMIxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Install Packages"
      ],
      "metadata": {
        "id": "Tu59smNlD4_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are quite a number of packages related to getting LLMs to fit and be trainable on a single GPU!"
      ],
      "metadata": {
        "id": "OSjJkdrwKhng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Track the total time to run all of the package installations.\n",
        "t0 = time.time()"
      ],
      "metadata": {
        "id": "IRDl857_gQIK"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install FlashAttention."
      ],
      "metadata": {
        "id": "VF2t5M7bD0ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtagTPOtDnIQ",
        "outputId": "bd6cc035-3715-43b5-b1fe-c376d1dea0a0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.5.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.2.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (24.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coLcwHyBHYko",
        "outputId": "ff6c1c18-29c2-45ee-82d0-36330395eb1b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upgrading pyarrow is a workaround for an error I was getting when trying to run `load_datasets`. It was the same error as reported [here](https://github.com/mgeraeds/hires-processing/issues/3)."
      ],
      "metadata": {
        "id": "i7RLHO3rggsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKurCmPUZjv9",
        "outputId": "4ea64294-d93f-4e70-c269-f08bba5bcdde"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfK8v2GgMzjc",
        "outputId": "feb70de9-b8fb-4d75-951f-93a748acc9ed"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I saw this installation in documentation [here](https://huggingface.co/docs/trl/lora_tuning_peft), but it may not be necessary?"
      ],
      "metadata": {
        "id": "4eEs18G85KSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loralib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOO8veHT5Gyl",
        "outputId": "42742d9d-786d-4c8f-f953-80c1de3f2875"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: loralib in /usr/local/lib/python3.10/dist-packages (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNkgErFPTL8S",
        "outputId": "936e907b-db5a-4a3a-f173-4dc10d0793ae"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.0.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjPaGJ8HgJn",
        "outputId": "a4532268-04c5-46e3-ad5f-0394561dc94e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgu0lXO_Hk-l",
        "outputId": "bd549e97-8cd0-453e-df94-c0e068fae453"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNTD9cN4HpQn",
        "outputId": "f5f414db-5bfc-4134-9157-130da530c13e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.40.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.29.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.19.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import these two packages to make sure I'm not encountering that error still."
      ],
      "metadata": {
        "id": "Tq7Da4nGKX1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow"
      ],
      "metadata": {
        "id": "vT6aS3AHMGLg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "igapQJp9ZB6o"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. HuggingFace Login"
      ],
      "metadata": {
        "id": "4lHTFKepLJLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mistral now requires you to log in to HuggingFace to download their model (and to accept their agreement [here](https://huggingface.co/mistralai/Mistral-7B-v0.1))\n",
        "\n",
        "TODO - Explain how to set this up."
      ],
      "metadata": {
        "id": "Jx1d32MSL0eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# I used the \"secrets\" panel in Colab and defined the variable\n",
        "# \"hf_hub_all_notebooks\" and set it to my personal huggingface key.\n",
        "# You could just paste in your key directly here if this is a private copy.\n",
        "hf_api_key = userdata.get('hf_hub_all_notebooks')\n",
        "\n",
        "!huggingface-cli login --token $hf_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z__GKLW-LLJQ",
        "outputId": "7673e8d0-d375-45d4-a1d2-cec61caaf3f0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Helper Functions"
      ],
      "metadata": {
        "id": "xF_p2XF-LsDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "BtoglSugH7fq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've got a helper function for allowing us to check out the memory usage of the model."
      ],
      "metadata": {
        "id": "mzhEpN7A-BM-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Ds6I7SReew"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "def check_gpu_mem():\n",
        "    '''\n",
        "    Uses Nvidia's SMI tool to check the current GPU memory usage.\n",
        "    '''\n",
        "\n",
        "    # Run the command line tool and get the results.\n",
        "    buf = os.popen('nvidia-smi --query-gpu=memory.total,memory.used --format=csv')\n",
        "\n",
        "    # Use csv module to read and parse the result.\n",
        "    reader = csv.reader(buf, delimiter=',')\n",
        "\n",
        "    # Use a pandas table just for nice formatting.\n",
        "    df = pd.DataFrame(reader)\n",
        "\n",
        "    # Use the first row as the column headers.\n",
        "    new_header = df.iloc[0] #grab the first row for the header\n",
        "    df = df[1:] #take the data less the header row\n",
        "    df.columns = new_header #set the header row as the df header\n",
        "\n",
        "    # Display the formatted table.\n",
        "    #display(df)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwNEQiomx5vL"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helper function prints out big numbers nicely using base 2 magnitudes (i.e., K = 2^10, M = 2^20, B = 2^30)"
      ],
      "metadata": {
        "id": "m0gamLDFx6Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_size(num):\n",
        "    \"\"\"\n",
        "    This function iterates through a list of suffixes ('K', 'M', 'B') and\n",
        "    divides the input number by 1024 until the absolute value of the number is\n",
        "    less than 1024. Then, it formats the number with the appropriate suffix and\n",
        "    returns the result. If the number is larger than \"B\", it uses 'T'.\n",
        "    \"\"\"\n",
        "    suffixes = ['', 'K', 'M', 'B']\n",
        "    base = 1024\n",
        "\n",
        "    for suffix in suffixes:\n",
        "        if abs(num) < base:\n",
        "            if num % 1 != 0:\n",
        "                return f\"{num:.2f}{suffix}\"\n",
        "\n",
        "            else:\n",
        "                return f\"{num:.0f}{suffix}\"\n",
        "\n",
        "        num /= base\n",
        "\n",
        "    # Use \"T\" for anything larger.\n",
        "    if num % 1 != 0:\n",
        "        return f\"{num:.2f}T\"\n",
        "\n",
        "    else:\n",
        "        return f\"{num:.0f}T\"\n",
        "\n"
      ],
      "metadata": {
        "id": "01Qv4iUQx6Cb"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All of that package installation stuff took:\", format_time(time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFhjqFsekQvl",
        "outputId": "c67b2cd3-a653-4a2d-ef82-493407eb0618"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All of that package installation stuff took: 0:00:59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the HuggingFace docs [here](https://huggingface.co/docs/transformers/v4.39.3/en/main_classes/model#transformers.PreTrainedModel.from_pretrained.attn_implementation):\n",
        "\n",
        "> \"if available, SDPA will be used for torch>=2.1.1. The default is otherwise the manual \"eager\" implementation.\"\n",
        "\n",
        "(Or check the latest documentation [here](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained.attn_implementation))."
      ],
      "metadata": {
        "id": "yujuuWRwaFze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7byCWb8aGhw",
        "outputId": "967cff74-3a20-488b-88ca-1508f24ffa1a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S2. Dataset"
      ],
      "metadata": {
        "id": "Gc14igVHKw8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace has a huge StackExchange dataset called `stack-exchange-preferences`, [here](https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences/), and this Notebook uses a variant of it called `stack-exchange-paired`, [here](https://huggingface.co/datasets/lvwerra/stack-exchange-paired).\n",
        "\n",
        "In the original dataset, each sample consists of a question plus multiple user answers.\n",
        "\n",
        "For the \"paired\" version, the samples consist instead of a question and only two user answers, labeled \"j\" and \"k\", where answer \"j\" is the preferred one.\n",
        "\n",
        "\n",
        "The dataset pages are a nice way to view some statistics and examples.\n",
        "\n",
        "For [stack-exchange-paired](https://huggingface.co/datasets/lvwerra/stack-exchange-paired):\n",
        "* It consists of 26.8M training samples and 4.48M test samples.\n",
        "* It's 26.3GB if you were to download it!\n",
        "\n",
        "They sampled \"at most 10 pairs per question\", which means you will see the **same question repeated** multiple times in the dataset, just with different response pairs.\n",
        "\n",
        "The Notebook used to create the 'paired' version of the dataset is [here](https://colab.research.google.com/#fileId=https%3A//huggingface.co/datasets/lvwerra/stack-exchange-paired/blob/main/StackExchangeProcessing.ipynb).\n",
        "\n",
        "The original `stack-exchange-preferences` dataset shows the full list of \"exchanges\" (topics) included in the dataset, [here](https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences/blob/main/stack_exchanges.json). There are 343 in total, but I imagine the distribution is heavily skewed (towards, e.g., programming)?"
      ],
      "metadata": {
        "id": "PTkEqZuCVHpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Stream Dataset"
      ],
      "metadata": {
        "id": "nXFgjIaz7NWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define arguments..."
      ],
      "metadata": {
        "id": "A0dcylQlNxh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "# Instantiate an empty Namespace object\n",
        "args = argparse.Namespace()\n",
        "\n",
        "# Define and set default values for attributes\n",
        "\n"
      ],
      "metadata": {
        "id": "gWMxcqKyJyi1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm using mistral-7b instead of LLaMa.\n",
        "\n",
        "Even though we're not loading the model till later on, we need to set this now in order to load the appropriate tokenizer."
      ],
      "metadata": {
        "id": "5XUkXEZ74Xr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.model_path = \"mistralai/Mistral-7B-v0.1\""
      ],
      "metadata": {
        "id": "4fRM23yj4VdQ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook, we're using the \"finetune\" portion of the dataset--though I don't know what the other subsets are?"
      ],
      "metadata": {
        "id": "AI_DvBVi4sXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset arguments\n",
        "args.dataset_name = \"lvwerra/stack-exchange-paired\"\n",
        "args.subset = \"data/finetune\""
      ],
      "metadata": {
        "id": "NAgTzQ8W4dVe"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Presumably there are train and test splits?"
      ],
      "metadata": {
        "id": "IkixvDlg47i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.split = \"train\""
      ],
      "metadata": {
        "id": "CDuZEmmB46g1"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be streaming the dataset. This is cool feature--rather than downloading the dataset in advance, we'll be pulling samples and processing them as we go. This eliminates a long pre-processing step, and doesn't appear to impact training speed. (I mean, think about the difference in complexity of manipulating some text vs. running a 7B parameter model!)"
      ],
      "metadata": {
        "id": "RHlLSonP5BV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.streaming = True\n",
        "\n",
        "# Related to streaming the dataset.\n",
        "args.shuffle_buffer = 5000"
      ],
      "metadata": {
        "id": "asSHqNyL4_0O"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is used during the dataset setup as part of the shuffling step...\n",
        "args.seed = 0"
      ],
      "metadata": {
        "id": "kwHyfmoC5vpM"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset... What does this do given that we're streaming?"
      ],
      "metadata": {
        "id": "tJeoHmy_PF3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Original call:\n",
        "#    train_dataset, eval_dataset = create_datasets(tokenizer, args)\n",
        "\n",
        "# This is a function from teh huggingface datasets library.\n",
        "dataset = load_dataset(\n",
        "    args.dataset_name, # \"lvwerra/stack-exchange-paired\"\n",
        "    data_dir = args.subset, # \"data/finetune\"\n",
        "    split = args.split, # \"train\"\n",
        "\n",
        "    #use_auth_token = True,\n",
        "\n",
        "    # We're streaming, so this is unnecessary.\n",
        "    #num_proc = args.num_workers if not args.streaming else None,\n",
        "\n",
        "    streaming = args.streaming, # \"True\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "RQHemiSfF2u0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e2619e4050ff415b8acda4f48feb8588",
            "5bd94337ce2c4e919d41c5e6263dfffa",
            "d36236e8922e41318ede69b00141786c",
            "38420a456340434db815d06ea47e0fc3",
            "354ba73e572543a8a7a9a07a8f82da46",
            "926e41df6ee54719992dc81a6796f40a",
            "d991d44099a64628a7bfe9369f548946",
            "7ad819705af4458f9ca76e3595993e8f",
            "750629903964429989e3a1e2d6610737",
            "d6b23a7a0bd149418c5871eb69df89f5",
            "1bf1f6d34eec4c5196d4b91fc5c98ca6"
          ]
        },
        "outputId": "a881f0a1-4c6f-4a52-ef0b-89bd12615b46"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2619e4050ff415b8acda4f48feb8588"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset))"
      ],
      "metadata": {
        "id": "J-7H3cvtPLkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d76384-c049-44f8-d951-461019420c54"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.iterable_dataset.IterableDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validation sets.\n",
        "\n",
        "TODO - What's going on in these two blocks?"
      ],
      "metadata": {
        "id": "Q3gsF5XE01VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The version 2 example has the validation set size at 4,000, which would take\n",
        "# a very long time on the T4--Much longer than the 500 training steps!\n",
        "# We're going to take 4,000 of the training samples out to use as our validation\n",
        "# set (for evaluating the model's performance mid-training).\n",
        "#args.size_valid_set = 4000\n",
        "args.size_valid_set = 50\n",
        "\n",
        "# We're streaming the dataset...\n",
        "if args.streaming:\n",
        "    print(\"Loading the dataset in streaming mode\")\n",
        "    valid_data = dataset.take(args.size_valid_set)\n",
        "    train_data = dataset.skip(args.size_valid_set)\n",
        "    train_data = train_data.shuffle(buffer_size=args.shuffle_buffer, seed=args.seed)\n",
        "\n",
        "# (Unused)\n",
        "else:\n",
        "    dataset = dataset.train_test_split(test_size=0.005, seed=args.seed)\n",
        "    train_data = dataset[\"train\"]\n",
        "    valid_data = dataset[\"test\"]\n",
        "    print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n"
      ],
      "metadata": {
        "id": "Qql8MkHgESTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da3af32-5190-4022-93c4-051de04674da"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset in streaming mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Inspect An Example"
      ],
      "metadata": {
        "id": "n6kpw2gDY9uA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print out an example from the dataset (I dug through the dataset a bit to find an interesting one)."
      ],
      "metadata": {
        "id": "F6wuwIgKMiGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Which example do we want to look at?\n",
        "example_i = 3172\n",
        "\n",
        "# Loop through the training examples to reach our desired index.\n",
        "# Note that this does actually retrieve the examples, so it's probably best not\n",
        "# to try and access one far in!\n",
        "for (i, example) in enumerate(dataset):\n",
        "\n",
        "    # Skip them until we reach the desired one.\n",
        "    if i == example_i:\n",
        "        print(example)\n",
        "\n",
        "        # Exit the loop.\n",
        "        break\n",
        "\n",
        "# Store this specific example to be used later when we check out the model's\n",
        "# performance prior to tuning.\n",
        "plucked_example = example"
      ],
      "metadata": {
        "id": "d9BrQu5YWdHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1cff7a-32a8-48fe-e59f-6e58d4925df5"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'qid': 8252, 'question': 'This question is only regarding aircraft that seat more than about 100 people. \\n\\nAre cargo holds pressurised these days, what is the situation?\\n\\nAre only some pressurized, most, of every single one? Does it depend on the carrier, operating region or are there other variations that matter?\\n\\nRelated questions:\\n\\n* Are cargo holds heated?\\n* Do they have lights? (Aren\\'t some lit for animals?)\\n* I\\'ve noticed random mentions of \"some\" of the sections being pressurised. Is this correct? It would seem to me that, if indeed, only **some** are pressurised then, of course, you absolutely could not **rely** on your luggage being in a pressurised area.\\n* and what about Fedex-type cargo-only aircraft?\\n\\nTo be clear, I ask this question re \"today\" because I noticed when googling on this, there is a lot of information, but only old information (say, 10 yrs old plus). That is a recipe for confusion and urban myth, so the total facts from you experts would be great.\\n\\n(Possibly, it would be difficult to secure accurate online references for this - my quick searching anyway only revealed patchy, out-of-date looking stuffs. Note for example, the Wikipedia article on [Cabin Pressurization](http://en.wikipedia.org/wiki/Cabin_pressurization) has only one poor, no-referenced sentence on the whole matter!)\\n\\nNote for example... [Spray bottles (pressurized) in the checked luggage?](https://travel.stackexchange.com/questions/35490)', 'date': '2014/08/20', 'metadata': ['https://aviation.stackexchange.com/questions/8252', 'https://aviation.stackexchange.com', 'https://aviation.stackexchange.com/users/3272/'], 'response_j': 'Aircraft design has not changed **that** much in the last 10 years. In fact, most aircraft in production 10 years ago are still in production.\\n\\nThe cargo holds in typical airliners are indeed pressurized. Take a look at a cross section of an airliner (A380 here):\\n\\n![A380 Fuselage Cross Section](https://i.stack.imgur.com/ytbmj.png)\\n\\nThe round shape of the fuselage outline is very efficient at withstanding pressure. Because of that, everything within the fuselage shape is pressurized. This includes the cargo hold below. Only cargo holds located behind the aft pressure bulkhead would be unpressurized, and these are mainly found in smaller aircraft.\\n\\nThe floor of the passenger cabin is not designed to withstand that pressure, because the flat surface would need to be much heavier to do so. Decompression events [are considered by regulations though](https://www.gpo.gov/fdsys/pkg/CFR-2011-title14-vol1/xml/CFR-2011-title14-vol1-sec25-365.xml), so there are vents that allow the pressure to equalize. In older aircraft without these vents, a decompression event can cause the floor of the cabin to collapse, as in [this incident](http://en.wikipedia.org/wiki/American_Airlines_Flight_96) (and because it wasn\\'t addressed, [this one too](http://en.wikipedia.org/wiki/Turkish_Airlines_Flight_981)).\\n\\n> \\n> Are cargo holds heated?\\n> \\n> \\n> \\n\\nSometimes. This will depend on the aircraft type. [There](http://www.airliners.net/aviation-forums/tech_ops/read.main/241772) [are](http://www.airliners.net/aviation-forums/tech_ops/read.main/275381/) [many](http://www.airliners.net/aviation-forums/tech_ops/read.main/75643/) [threads](http://www.airliners.net/aviation-forums/tech_ops/read.main/13748) over on the TechOps forums about this. The temperature can be adjusted depending on the cargo load.\\n\\nAlthough the air outside the plane is cold, the walls are insulated (also for fire protection), and being pressurized along with the cabin helps too. Even in unheated cargo holds, the temperature should be above freezing. For example, [the cargo bay of a 767 stays above 7˚C but with heat stays above 18˚C](https://travel.stackexchange.com/q/22604/12976).\\n\\n> \\n> Do they have lights? (Aren\\'t some lit for animals?)\\n> \\n> \\n> \\n\\nThey do have lights, mainly for ground crew during loading and unloading. See [this Boeing page](http://www.boeing.com/commercial/aeromagazine/aero_06/textonly/s01txt.html) about fire protection where it mentions that \"another safety feature on many newer airplane models prevents the cargo lights from operating in flight\".\\n\\n> \\n> and what about Fedex-type cargo-only aircraft?\\n> \\n> \\n> \\n\\nThese aircraft are still based on the airliner models (and sometimes converted from airliners). Therefore, they have the same pressurization system. The cabin is still pressurized, or they would have to put in some type of bulkhead behind the cockpit.\\n\\n[This includes](http://www.acp-logistics.com/boeing-b747-400f-charter.html) the cargo version of the 747 (both upper and lower areas are pressurized).\\n\\nThe rare exception would be aircraft like the 747 LCF (Dreamlifter). The cargo section [is not pressurized](http://www.boeing.com/news/frontiers/archive/2005/june/ts_sf05.html), and there is a bulkhead behind the flight deck section.', 'response_k': 'Yes, they are pressurized and climate controlled, especially on commercial flights where live cargo eg pets, bees, chicks, etc may be loaded aboard in the spaces and would be lethal to the creatures to be in a space at subzero temperatures and without supplemental oxygen encountered during cruise at high altitudes.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The example is stored as a dictionary, and the questions and responses are tricky to display nicely.\n",
        "\n",
        "We'll use `pandas` first to print a compact view of the example."
      ],
      "metadata": {
        "id": "W5EzhsrtMfAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dataframe from all of the key-value pairs in the dictionary.\n",
        "df = pd.DataFrame(list(example.items()), columns=[\"Key\", \"Value\"])\n",
        "\n",
        "# Use Colab / Jupyter's table rendering.\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "8T9sI1RXYjAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e73c89f5-e905-4142-9dd2-eb618b820b99"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Key                                              Value\n",
              "0         qid                                               8252\n",
              "1    question  This question is only regarding aircraft that ...\n",
              "2        date                                         2014/08/20\n",
              "3    metadata  [https://aviation.stackexchange.com/questions/...\n",
              "4  response_j  Aircraft design has not changed **that** much ...\n",
              "5  response_k  Yes, they are pressurized and climate controll..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b755955-22f4-40c6-b325-9f91dfa2ba4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Key</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qid</td>\n",
              "      <td>8252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>question</td>\n",
              "      <td>This question is only regarding aircraft that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>date</td>\n",
              "      <td>2014/08/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metadata</td>\n",
              "      <td>[https://aviation.stackexchange.com/questions/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>response_j</td>\n",
              "      <td>Aircraft design has not changed **that** much ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>response_k</td>\n",
              "      <td>Yes, they are pressurized and climate controll...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b755955-22f4-40c6-b325-9f91dfa2ba4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b755955-22f4-40c6-b325-9f91dfa2ba4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b755955-22f4-40c6-b325-9f91dfa2ba4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-353cc0d0-7aaf-492e-a2af-67cc4803d8e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-353cc0d0-7aaf-492e-a2af-67cc4803d8e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-353cc0d0-7aaf-492e-a2af-67cc4803d8e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"qid\",\n          \"question\",\n          \"response_k\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To print out the full strings nicely, we can try using the `tabulate` library to format them into an ASCII table."
      ],
      "metadata": {
        "id": "BbcYBfJdOiOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "id": "0ZHlOnd9XYyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324109b4-77c8-4a6d-ad0b-11b40f90f095"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# The table will have two columns, for the keys and values.\n",
        "headers = [\"Key\", \"Value\"]\n",
        "\n",
        "# Add each key-value pair in the dictionary.\n",
        "rows = [[key, value] for key, value in example.items()]\n",
        "\n",
        "table_str = tabulate(rows,\n",
        "                     headers = headers,\n",
        "                     tablefmt = \"grid\")\n",
        "\n",
        "print(table_str)"
      ],
      "metadata": {
        "id": "OhzdOqy_XX3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4233e9-1b20-4eba-a6f4-fb12bd444b61"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Key        | Value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "+============+=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n",
            "| qid        | 8252                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| question   | This question is only regarding aircraft that seat more than about 100 people.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Are cargo holds pressurised these days, what is the situation?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Are only some pressurized, most, of every single one? Does it depend on the carrier, operating region or are there other variations that matter?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Related questions:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | * Are cargo holds heated?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|            | * Do they have lights? (Aren't some lit for animals?)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|            | * I've noticed random mentions of \"some\" of the sections being pressurised. Is this correct? It would seem to me that, if indeed, only **some** are pressurised then, of course, you absolutely could not **rely** on your luggage being in a pressurised area.                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | * and what about Fedex-type cargo-only aircraft?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | To be clear, I ask this question re \"today\" because I noticed when googling on this, there is a lot of information, but only old information (say, 10 yrs old plus). That is a recipe for confusion and urban myth, so the total facts from you experts would be great.                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | (Possibly, it would be difficult to secure accurate online references for this - my quick searching anyway only revealed patchy, out-of-date looking stuffs. Note for example, the Wikipedia article on [Cabin Pressurization](http://en.wikipedia.org/wiki/Cabin_pressurization) has only one poor, no-referenced sentence on the whole matter!)                                                                                                                                                                                                                                                                                                                       |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Note for example... [Spray bottles (pressurized) in the checked luggage?](https://travel.stackexchange.com/questions/35490)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| date       | 2014/08/20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| metadata   | ['https://aviation.stackexchange.com/questions/8252', 'https://aviation.stackexchange.com', 'https://aviation.stackexchange.com/users/3272/']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| response_j | Aircraft design has not changed **that** much in the last 10 years. In fact, most aircraft in production 10 years ago are still in production.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | The cargo holds in typical airliners are indeed pressurized. Take a look at a cross section of an airliner (A380 here):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | ![A380 Fuselage Cross Section](https://i.stack.imgur.com/ytbmj.png)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | The round shape of the fuselage outline is very efficient at withstanding pressure. Because of that, everything within the fuselage shape is pressurized. This includes the cargo hold below. Only cargo holds located behind the aft pressure bulkhead would be unpressurized, and these are mainly found in smaller aircraft.                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | The floor of the passenger cabin is not designed to withstand that pressure, because the flat surface would need to be much heavier to do so. Decompression events [are considered by regulations though](https://www.gpo.gov/fdsys/pkg/CFR-2011-title14-vol1/xml/CFR-2011-title14-vol1-sec25-365.xml), so there are vents that allow the pressure to equalize. In older aircraft without these vents, a decompression event can cause the floor of the cabin to collapse, as in [this incident](http://en.wikipedia.org/wiki/American_Airlines_Flight_96) (and because it wasn't addressed, [this one too](http://en.wikipedia.org/wiki/Turkish_Airlines_Flight_981)). |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | > Are cargo holds heated?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Sometimes. This will depend on the aircraft type. [There](http://www.airliners.net/aviation-forums/tech_ops/read.main/241772) [are](http://www.airliners.net/aviation-forums/tech_ops/read.main/275381/) [many](http://www.airliners.net/aviation-forums/tech_ops/read.main/75643/) [threads](http://www.airliners.net/aviation-forums/tech_ops/read.main/13748) over on the TechOps forums about this. The temperature can be adjusted depending on the cargo load.                                                                                                                                                                                                    |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | Although the air outside the plane is cold, the walls are insulated (also for fire protection), and being pressurized along with the cabin helps too. Even in unheated cargo holds, the temperature should be above freezing. For example, [the cargo bay of a 767 stays above 7˚C but with heat stays above 18˚C](https://travel.stackexchange.com/q/22604/12976).                                                                                                                                                                                                                                                                                                     |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | > Do they have lights? (Aren't some lit for animals?)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | They do have lights, mainly for ground crew during loading and unloading. See [this Boeing page](http://www.boeing.com/commercial/aeromagazine/aero_06/textonly/s01txt.html) about fire protection where it mentions that \"another safety feature on many newer airplane models prevents the cargo lights from operating in flight\".                                                                                                                                                                                                                                                                                                                                    |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | > and what about Fedex-type cargo-only aircraft?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            | >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | These aircraft are still based on the airliner models (and sometimes converted from airliners). Therefore, they have the same pressurization system. The cabin is still pressurized, or they would have to put in some type of bulkhead behind the cockpit.                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | [This includes](http://www.acp-logistics.com/boeing-b747-400f-charter.html) the cargo version of the 747 (both upper and lower areas are pressurized).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|            | The rare exception would be aircraft like the 747 LCF (Dreamlifter). The cargo section [is not pressurized](http://www.boeing.com/news/frontiers/archive/2005/june/ts_sf05.html), and there is a bulkhead behind the flight deck section.                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| response_k | Yes, they are pressurized and climate controlled, especially on commercial flights where live cargo eg pets, bees, chicks, etc may be loaded aboard in the spaces and would be lethal to the creatures to be in a space at subzero temperatures and without supplemental oxygen encountered during cruise at high altitudes.                                                                                                                                                                                                                                                                                                                                            |\n",
            "+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each training sample, we combine the question and the answer (specifically, 'response_j') into a single string with some added formatting.\n",
        "\n",
        "If the question is \"What color is the sky?\" and the answer is \"The sky is blue.\", then this will be formatted as:\n",
        "\n",
        "```\n",
        "Question: What color is the sky?\n",
        "\n",
        "Answer: The sky is blue.\n",
        "```\n",
        "\n",
        "I thought it was interesting to see that they insert the blank line in between, implying that these models would find that little bit of whitespace meaningful (in the same way we would)."
      ],
      "metadata": {
        "id": "ZYWbR3Gmvfy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sample_text(example):\n",
        "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
        "\n",
        "    # Label the question and the answer, and add a blank line in between. For\n",
        "    # example:\n",
        "    #\n",
        "    # Question: What color is the sky?\n",
        "    #\n",
        "    # Answer: The sky is blue.\n",
        "    text = f\"Question: {example['question']}\\n\\nAnswer: {example['response_j']}\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "MeFFAc1yNruK"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can demonstrate the formatting with a small example."
      ],
      "metadata": {
        "id": "AlEzwAekPGfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex = {}\n",
        "\n",
        "ex['question'] = \"What color is the sky?\"\n",
        "ex['response_j'] = \"The sky is blue.\"\n",
        "\n",
        "prepare_sample_text(ex)"
      ],
      "metadata": {
        "id": "aqaHiPN1vXSC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ff7afb72-0d57-48e4-ffec-d112d3d6ce80"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: What color is the sky?\\n\\nAnswer: The sky is blue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Sample Length Distribution"
      ],
      "metadata": {
        "id": "9xuQPLASNgE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authors of the example chose a maximum sequence length of 1024. I'm curious to see how this corresponds to the actual lengths of the examples, so let's plot the distribution of lengths.\n",
        "\n",
        "To get the lengths, we'll need to tokenize the examples."
      ],
      "metadata": {
        "id": "ppOjC6p_PMSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_path)\n"
      ],
      "metadata": {
        "id": "L1JdKJlMIGZU"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO** - There are a couple of lines here that seem like they could be rather critical, but I'm not sure why or what they're really about.\n",
        "\n",
        "These did not appear in version 1 of the StackLLaMA example, but are in version 2.\n",
        "\n",
        "Also, because I'm running with Mistral 7B instead of LLaMA 2, it's possible that these changes don't apply, or that different changes should be made! 😳"
      ],
      "metadata": {
        "id": "hjLLj02wY40x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.pad_token)\n",
        "print(tokenizer.eos_token)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSKQmzVsY4aG",
        "outputId": "ed125f7d-a4f1-4031-b60f-179e2568aa2f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.padding_side)\n",
        "\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHGA0533ZSeX",
        "outputId": "e0df0798-bb57-418c-bffa-ef2691b854b9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "left\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What Tokenizer is being used?\n",
        "(I don't have any interesting insights from this)"
      ],
      "metadata": {
        "id": "wEQit9IzPfiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "ZNhljUPjNG84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75542d53-f694-407e-f800-392b988511e7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a number of questions surrounding sequence length at this point:\n",
        "\n",
        "* How important is it for the example to fit within a single context window?\n",
        "* How do the various new tricks around expanded context windows impact this parameter, and what's their impact during training vs. inference?\n"
      ],
      "metadata": {
        "id": "a3sXzoIfVGEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The model will be given examples of this length.\n",
        "# This parameter has a big impact on training speed and memory consumption\n",
        "# because of the attention calculations--we calculate attention between every\n",
        "# token and every other token (though for GPT we discard half of these values).\n",
        "# This means there are (sequence length)^2 attention scores calculated at\n",
        "# each of the model's 32 layers, and we have to store these for training.\n",
        "\n",
        "args.seq_length = 1024\n",
        "\n",
        "#args.seq_length = 512"
      ],
      "metadata": {
        "id": "X8u6Kbf26Eyw"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot the sample length distribution, let's tokenize a small subset of the dataset and tally up the sample lengths.\n",
        "\n",
        "> Note: In the next section on \"example packing\", we're going to need to have an estimate of the average number of characters per token in the dataset, so we'll gather that statistic here as well."
      ],
      "metadata": {
        "id": "si4o05bnMpWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print('Gathering sample length statistics...')\n",
        "\n",
        "# We'll gather statistics from a subset of the dataset.\n",
        "nb_examples = 3000\n",
        "\n",
        "# We'll store the token lengths of the samples so that we can plot a\n",
        "# histogram to check out their distribution.\n",
        "token_lengths = []\n",
        "\n",
        "# We're also going to calculate the average number of characters per token\n",
        "# because this is needed later for \"example packing\".\n",
        "total_characters = 0\n",
        "total_tokens = 0\n",
        "\n",
        "# For each of the examples... (use tqdm to render a progress bar)\n",
        "for _, example in tqdm(zip(range(nb_examples), iter(train_data)),\n",
        "                       total = nb_examples):\n",
        "\n",
        "    # Prepare a training sample by combining the question and answer with some\n",
        "    # formatting.\n",
        "    text = prepare_sample_text(example)\n",
        "\n",
        "    # Add the total characters in this sample to the running total.\n",
        "    total_characters += len(text)\n",
        "\n",
        "    # Tokenize the example, just to get the number of tokens it turns into.\n",
        "    # Apparently the syntax for tokenizing is different depending on whether\n",
        "    # it's a \"fast\" type tokenizer.\n",
        "    # (In this example, we are using a \"fast\" one.)\n",
        "    if tokenizer.is_fast:\n",
        "        ex_num_tokens = len(tokenizer(text).tokens())\n",
        "    else:\n",
        "        ex_num_tokens = len(tokenizer.tokenize(text))\n",
        "\n",
        "    # Add the number to the running total.\n",
        "    total_tokens += ex_num_tokens\n",
        "\n",
        "    # Add the number to the list so we can later plot the distribution.\n",
        "    token_lengths.append(ex_num_tokens)\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "id": "ozedB5QlEVwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d597d11b-1aa0-4751-83cb-9438c6b6aa4f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gathering sample length statistics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:07<00:00, 400.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlDRkaLmz-RU"
      },
      "source": [
        "Let's grab some quick statistics--what are the min, max and median comment lengths from this subset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA2VcRxbz-Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee97e0a4-0204-4114-8f0e-01450f4e0a2c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('   Min length: {:,} tokens'.format(min(token_lengths)))\n",
        "print('   Max length: {:,} tokens'.format(max(token_lengths)))\n",
        "print('Median length: {:,} tokens'.format(int(np.median(token_lengths))))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Min length: 46 tokens\n",
            "   Max length: 8,186 tokens\n",
            "Median length: 441 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AuFEoruz-Re"
      },
      "source": [
        "To further analyze it, let's plot the distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TYXnmS9z-Rf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "82887144-73ac-42e2-c22e-35ef90afb995"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.histplot(token_lengths)\n",
        "\n",
        "plt.title('Sample Lengths')\n",
        "plt.xlabel('Sample Length')\n",
        "plt.ylabel('# of Samples')\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Samples')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSUG492X0ipi"
      },
      "source": [
        "Looking at this plot, it seems like 1,024 is a reasonable choice near the \"elbow\" of the curve.\n",
        "\n",
        "More concretely, how many samples are going to be cut short?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPAsP_VY0ipj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293959a5-8d97-41ce-c732-7bded281cf77"
      },
      "source": [
        "print('For a maximum sequence length of {:,}...'.format(args.seq_length))\n",
        "\n",
        "# How many of the examples are longer than X tokens?\n",
        "num_truncated = np.sum(np.asarray(token_lengths) > args.seq_length)\n",
        "\n",
        "# Sanity check\n",
        "assert(len(token_lengths) == nb_examples)\n",
        "\n",
        "# Calculate the percentage that are truncated.\n",
        "prcnt = float(num_truncated) / float(nb_examples)\n",
        "\n",
        "print('{:,} of {:,} examples ({:.1%}) will be truncated.'.format(num_truncated, nb_examples, prcnt))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a maximum sequence length of 1,024...\n",
            "393 of 3,000 examples (13.1%) will be truncated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Example Packing"
      ],
      "metadata": {
        "id": "sD23-ExAZYit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example packing is \"where multiple short examples are packed in the same input sequence to increase training efficiency. This is done with the ConstantLengthDataset utility class that returns constant length chunks of tokens from a stream of examples.\" (from [here](https://huggingface.co/docs/trl/en/sft_trainer))."
      ],
      "metadata": {
        "id": "y1ZXZ6YN1snn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, we tallied up the total characters and total tokens from a subset of the dataset, and we'll use this to estimate the average number of characters per token.\n",
        "\n",
        "The `ConstantLengthDataset` uses this estimate in some way--perhaps as a way to make an initial guess at the token count for a sample, to decide whether to try packing particular samples together?"
      ],
      "metadata": {
        "id": "c_krOrIIXlgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate the average number of characters per token (for example packing)\n",
        "chars_per_token = total_characters / total_tokens\n",
        "\n",
        "print(f\"\\n\\nThe character to token ratio of the dataset is: {chars_per_token:.2f}\")"
      ],
      "metadata": {
        "id": "GcTIZFnPXkuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457660b0-4ac6-4d02-b490-85529e24374c"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The character to token ratio of the dataset is: 3.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl.trainer import ConstantLengthDataset\n",
        "\n",
        "train_dataset = ConstantLengthDataset(\n",
        "\n",
        "    # Pass in the original dataset, and the tokenizer.\n",
        "    tokenizer,\n",
        "    train_data,\n",
        "\n",
        "    # The dataset hasn't been formatted into \"Question: --- Answer: ---\" yet;\n",
        "    # we give this a handle to our function to do it for us.\n",
        "    formatting_func = prepare_sample_text,\n",
        "\n",
        "    infinite = True, # TODO - Probably that we're not just going to do a single\n",
        "                     #        pass over the dataset, so it's ok to re-use\n",
        "                     #        samples.\n",
        "\n",
        "    # We have to provide a sequence length we want to use!\n",
        "    seq_length = args.seq_length,\n",
        "\n",
        "    # The utility class wants to know this dataset statistic. It must use it\n",
        "    # to help make some initial decisions.\n",
        "    chars_per_token = chars_per_token\n",
        ")\n",
        "\n",
        "# Do the same thing for the validation dataset. Infinite is false, though.\n",
        "valid_dataset = ConstantLengthDataset(\n",
        "    tokenizer,\n",
        "    valid_data,\n",
        "    formatting_func=prepare_sample_text,\n",
        "    infinite=False,\n",
        "    seq_length=args.seq_length,\n",
        "    chars_per_token=chars_per_token,\n",
        ")\n"
      ],
      "metadata": {
        "id": "SIUHxyNXIvkY"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - This was in the original example, and I'm not clear on the purpose.\n",
        "train_dataset.start_iteration = 0"
      ],
      "metadata": {
        "id": "-_HeeccM37c4"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S3. Load & Inspect Model"
      ],
      "metadata": {
        "id": "kkmmDyWwbygW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how much GPU memory we have, and how much is used prior to loading the model. (`check_gpu_mem` was defined up in section 1.2.)"
      ],
      "metadata": {
        "id": "Sv8taaPZa4lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out memory useage prior to loading.\n",
        "check_gpu_mem()"
      ],
      "metadata": {
        "id": "oQG1ujeE9j9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9739af76-d5b4-48f9-af44-081516e075d0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0 memory.total [MiB]  memory.used [MiB]\n",
              "1          15360 MiB           5741 MiB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31c8b7bd-ecd4-42fd-a9a9-d34588925d6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>memory.total [MiB]</th>\n",
              "      <th>memory.used [MiB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15360 MiB</td>\n",
              "      <td>5741 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31c8b7bd-ecd4-42fd-a9a9-d34588925d6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31c8b7bd-ecd4-42fd-a9a9-d34588925d6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31c8b7bd-ecd4-42fd-a9a9-d34588925d6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"check_gpu_mem()\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"memory.total [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"15360 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" memory.used [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" 5741 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. 4-bit Quantization"
      ],
      "metadata": {
        "id": "LRK3d0tmakgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How it Works**\n",
        "\n",
        "Unlike reducing precision (e.g., going from 32-bit parameters down to 16-bit), 4-bit quantization is more like a **compression** technique, where the stored values **aren't useable** until they're decompressed again.\n",
        "\n",
        "(Simply rounding down to 4-bits would be insane--that's only 16 unique values!)\n",
        "\n",
        "The weight values are broken down into a **4-bit base value** multiplied by a **16-bit scaling factor**.\n",
        "\n",
        "...but that uses _more_ memory than before (20-bits per value), not less! 🤨\n",
        "\n",
        "In order to actually compress the data, every **64 values** in the weights will all share a single 16-bit scaling factor.\n",
        "\n",
        "(The number 64 is called the \"block size\", and seems to be hardcoded into the algorithm).\n",
        "\n",
        "If you do the math--64 values that originally required 128 bytes to store now require 34 bytes in compressed form. A compression ratio of **3.76x**.\n",
        "\n",
        "In order for the weights to actually be useable in calculations, we have to **decompress** them by multiplying the 4-bit values with their corresponding scaling factor to get back (roughly?) the original values at 16-bit precision.\n",
        "\n",
        "I have a more in-depth tutorial on quantization here - **TODO**"
      ],
      "metadata": {
        "id": "mnypTkoBar7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Running Quantization**\n",
        "\n",
        "When we call `from_pretrained`, it's going to download the full-sized model from huggingface (according to the progress bar it's about 14.5GB), and then run this compression algorithm on the weights before loading the model onto the GPU.\n",
        "\n",
        "An interesting consequence of applying quantization is that it's not possible to make updates to quantized weights! We'd have to re-run compression after every training step.\n",
        "\n",
        "This means we have to freeze those parameters, and use LoRA in order to actually fine-tune the model. This adds additional weights for us to tune instead.\n",
        "\n",
        "(Note: Quantization doesn't get applied to the layer normalization weights, the input embeddings, or the final language model output head.)"
      ],
      "metadata": {
        "id": "XPEiBk9pk747"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StackLLaMA 1 vs. 2**\n",
        "\n",
        "Version 1 used 8-bit quantization [here](https://github.com/huggingface/trl/blob/57aebe9c36021e679662181468b04ff42432daf3/examples/research_projects/stack_llama/scripts/supervised_finetuning.py#L172), but version 2 used 4-bit quantization [here](https://github.com/huggingface/trl/blob/57aebe9c36021e679662181468b04ff42432daf3/examples/research_projects/stack_llama_2/scripts/sft_llama2.py#L149).\n",
        "\n",
        "They did not use double quantization--I think this technique may only save a modest amount of memory, presumably slows the model down, and I'm not sure what impact it has on model quality."
      ],
      "metadata": {
        "id": "UAaZ_dq6oWer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the configuration object for setting up 4-bit quantization."
      ],
      "metadata": {
        "id": "tDifs5nBefTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    # Enable 4-bit quantization.\n",
        "    load_in_4bit = True,\n",
        "\n",
        "    # With \"double quantization\" we not only compress the weights, we compress\n",
        "    # the scaling factors as well!\n",
        "    bnb_4bit_use_double_quant = False,\n",
        "\n",
        "    # The authors did some analysis of the distribution of weight values in\n",
        "    # popular transformer models, and chose some hardcoded values to use as the\n",
        "    # 16 \"base values\", which seem to better allocate the available precision.\n",
        "    # You can use these hardcoded values by choosing \"nf4\".\n",
        "    #\n",
        "    # The alternative choice is \"float4\", which presumably just uniformly\n",
        "    # distributes the 16 base values.\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "\n",
        "    # Pretty sure this is the precision of the scaling factors.\n",
        "    # It may be that the key choice here is 'float16' vs. 'bfloat16' -- I'm\n",
        "    # sure we want it to match what's used for the model and for LoRA.\n",
        "    # If T4:\n",
        "    bnb_4bit_compute_dtype = torch.float16\n",
        "    #bnb_4bit_compute_dtype = torch.bfloat16\n",
        "\n",
        "    # Note that the \"block size\" of 64, which determines the compression ratio,\n",
        "    # doesn't appear to be configurable!\n",
        ")"
      ],
      "metadata": {
        "id": "5SV5an6-edUj"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Download Model"
      ],
      "metadata": {
        "id": "F3f7OH9bann6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will:\n",
        "\n",
        "* Download the model (about 14.5GB)\n",
        "* Compress it, following the quantization configuration\n",
        "* Load it onto the GPU."
      ],
      "metadata": {
        "id": "cfaqZyUE9C_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import AutoModelForCausalLM\n",
        "from transformers import MistralForCausalLM\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(\n",
        "\n",
        "model = MistralForCausalLM.from_pretrained(\n",
        "\n",
        "    args.model_path, # \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "    # Our 4-bit quantization setup defined in the previous section.\n",
        "    quantization_config = bnb_config,\n",
        "\n",
        "    # Currently, you can't use this unless you're running an A100 or L4.\n",
        "    #attn_implementation = \"flash_attention_2\",\n",
        "\n",
        "    attn_implementation = \"sdpa\",\n",
        "    #attn_implementation = \"eager\",\n",
        "\n",
        "    # I assume it's critical that this datatype match the one used in\n",
        "    # the quantization configuration, and in LoRA!\n",
        "    #torch_dtype = torch.bfloat16,\n",
        "    # If T4:\n",
        "    torch_dtype = torch.float16,\n",
        "\n",
        "    # I was getting this output message:\n",
        "    #    \"`low_cpu_mem_usage` was None, now set to True since model is\n",
        "    #      quantized.\"\n",
        "    # So I'm setting it to \"True\" as the message suggests. :)\n",
        "    #\n",
        "    # I tried setting it to False out of curiousity, and it crashed with:\n",
        "    #    \"Your session crashed after using all available RAM.\"\n",
        "    low_cpu_mem_usage = True,\n",
        "\n",
        ")\n",
        "\n",
        "print(\"\\nDownloading / loading model took\", format_time(time.time() - t0))\n"
      ],
      "metadata": {
        "id": "3ABj4sfeBnuk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "17a9619df1364fbe896e0678401866bb",
            "82593e74a87a4cf38d457dbf2cc182ab",
            "2282cc32a4f04e60b4d541ca9357d0c0",
            "838daf2bb0be44439c4020ab5c507321",
            "72f6f1924ff54484b8681a3ecc2fe9cb",
            "34cf30478e2446e0a62ee69f89820e5a",
            "a7b3ed3e609a4fc68c470eef0415f872",
            "3eef5d550d1b45a48073faceb9e5e79a",
            "b534fa8f6d4f40ceac4d896f5b9240d8",
            "7f262ac1b5e7475c84c96ae2e69deab3",
            "daa1730e4d5846f78daf56deed0018da"
          ]
        },
        "outputId": "bd7bd8e6-7ba5-4c31-b570-6a208febb6ba"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a9619df1364fbe896e0678401866bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading / loading model took 0:00:13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not sure what this does (this comes from the huggingface code)."
      ],
      "metadata": {
        "id": "mgjAvcuNYe3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "s8mYWaD3YigT"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm always curious what the actual class name is... 😊"
      ],
      "metadata": {
        "id": "q1Am-L4N-jJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))"
      ],
      "metadata": {
        "id": "IZgMN_UyOg-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ec084c-bdae-49f5-f7f8-ff88cf821f75"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.mistral.modeling_mistral.MistralForCausalLM'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It'd be interesting to grab, for comparison, the memory consumption for 4-bit quantization vs. 8-bit, and how much is saved by further compressing the scaling factors using \"double quantization\".\n",
        "\n",
        "Also, I noticed that the memory consumption is actually different between the T4 and A100, presumably because they support some different CUDA features."
      ],
      "metadata": {
        "id": "GEDWRx6F-o9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# And now memory usage after loading.\n",
        "check_gpu_mem()"
      ],
      "metadata": {
        "id": "iDSuBONM9o9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "2c31953d-ef73-429d-916c-613acea2cce7"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0 memory.total [MiB]  memory.used [MiB]\n",
              "1          15360 MiB          10443 MiB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39466434-8a07-4dc5-8168-8882f204ff2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>memory.total [MiB]</th>\n",
              "      <th>memory.used [MiB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15360 MiB</td>\n",
              "      <td>10443 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39466434-8a07-4dc5-8168-8882f204ff2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39466434-8a07-4dc5-8168-8882f204ff2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39466434-8a07-4dc5-8168-8882f204ff2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"check_gpu_mem()\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"memory.total [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"15360 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" memory.used [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" 10443 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing out the model architecture can be informative...\n",
        "\n",
        "I thought it was interesting to see:\n",
        "\n",
        "* 32 layers\n",
        "* 4,096 embedding size\n",
        "* The weight matrices are replaced with quantized versions named Linear4bit"
      ],
      "metadata": {
        "id": "kXBWEFMYBcyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "g0z6t8m1AM-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb1b621-ae1d-428e-ca77-b1cbc45662b8"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): MistralRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm()\n",
              "        (post_attention_layernorm): MistralRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S4. Performance Before Tuning"
      ],
      "metadata": {
        "id": "DkXGgMzmsW0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO** - Pick some interesting examples to evaluate the model on, and add some reflections about it."
      ],
      "metadata": {
        "id": "geD97Xh8sYLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Earlier in the Notebook, we selected a specific example to look at and play\n",
        "# with.\n",
        "example = plucked_example\n",
        "\n",
        "text = f\"Question: {example['question']}\\n\\nAnswer: \"\n",
        "\n",
        "#Desired answer: {example['response_j']}"
      ],
      "metadata": {
        "id": "3z2DYmGdthK5"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "OQdUx-aQScdR"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\"\n",
        "\n",
        "# Tokenize the text, which returns it as a list of token ids.\n",
        "input_ids = tokenizer(\n",
        "    text,\n",
        "    return_tensors = \"pt\" # Return them in a Pytorch Tensor.\n",
        ")\n",
        "\n",
        "# Move them to the GPU.\n",
        "input_ids = input_ids.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed it in and generate output!\n",
        "\n",
        "# These settings come from the widget in their blog post (I believe they are\n",
        "# the defaults they set for the widget?), except I doubled the sequence length.\n",
        "outputs = model.generate(**input_ids,\n",
        "                         max_length=1024,\n",
        "\n",
        "                         do_sample = True,\n",
        "                         temperature = 0.9,\n",
        "                         top_p = 0.9,\n",
        "                         repetition_penalty = 1.2)\n",
        "\n",
        "# Using defaults instead:\n",
        "#outputs = model.generate(**input_ids)"
      ],
      "metadata": {
        "id": "PaOzQ1YxtuGg"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the input + output tokens back into readable text.\n",
        "full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "4hW0jUvPyeru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print it all out, wrap to 80 characters wide.\n",
        "\n",
        "**TODO** - Address linebreak issues following advice [here](https://stackoverflow.com/questions/1166317/python-textwrap-library-how-to-preserve-line-breaks)."
      ],
      "metadata": {
        "id": "D6GmmxeRyXDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(\n",
        "    width = 80,\n",
        "    break_long_words = False,\n",
        "    replace_whitespace = False\n",
        ")\n",
        "\n",
        "\n",
        "print(wrapper.fill(full_text))"
      ],
      "metadata": {
        "id": "8Nx-OcDcuaOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a773889b-2cf2-4ebd-fab7-950a53a328b1"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: This question is only regarding aircraft that seat more than about 100\n",
            "people. \n",
            "\n",
            "Are cargo holds pressurised these days, what is the situation?\n",
            "\n",
            "Are\n",
            "only some pressurized, most, of every single one? Does it depend on the carrier,\n",
            "operating region or are there other variations that matter?\n",
            "\n",
            "Related questions:\n",
            "* Are cargo holds heated?\n",
            "* Do they have lights? (Aren't some lit for animals?)\n",
            "* I've noticed random mentions of \"some\" of the sections being pressurised. Is\n",
            "this correct? It would seem to me that, if indeed, only **some** are pressurised\n",
            "then, of course, you absolutely could not **rely** on your luggage being in a\n",
            "pressurised area.\n",
            "* and what about Fedex-type cargo-only aircraft?\n",
            "\n",
            "To be clear,\n",
            "I ask this question re \"today\" because I noticed when googling on this, there is\n",
            "a lot of information, but only old information (say, 10 yrs old plus). That is a\n",
            "recipe for confusion and urban myth, so the total facts from you experts would\n",
            "be great.\n",
            "\n",
            "(Possibly, it would be difficult to secure accurate online references\n",
            "for this - my quick searching anyway only revealed patchy, out-of-date looking\n",
            "stuffs. Note for example, the Wikipedia article on [Cabin\n",
            "Pressurization](http://en.wikipedia.org/wiki/Cabin_pressurization) has only one\n",
            "poor, no-referenced sentence on the whole matter!)\n",
            "\n",
            "Note for example... [Spray\n",
            "bottles (pressurized) in the checked\n",
            "luggage?](https://travel.stackexchange.com/questions/35490)\n",
            "\n",
            "Answer: \n",
            "I am\n",
            "assuming you mean airplanes carrying both passengers AND freight together. In\n",
            "those cases, the forward hold is unpressurized unless an all-freighter\n",
            "conversion was done on the plane at some point. \n",
            "\n",
            "There should still be an\n",
            "emergency oxygen mask for crew use if needed as well as life rafts if the\n",
            "forward hold will sink into water in case of ditching or crash landing on water.\n",
            "The rest of the rear cabin can either be used for baggage or extra seating\n",
            "depending on how much room is available behind the last row of seats. A typical\n",
            "widebody like a Boeing 767-300ER or Airbus A330-200 will carry approximately 25\n",
            "metric tons (about 8 million cubic feet / 230 m^3 ) of baggage/cargo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparison, here is [what ChatGPT has to say](https://chat.openai.com/share/fa3973db-0d1f-4538-b639-8c630f4da658) about pressurized cargo holds (short answer--yes, they're pressurized)."
      ],
      "metadata": {
        "id": "otaVXrc7zDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S5. Training with Low Memory"
      ],
      "metadata": {
        "id": "ZZ4wXb5ZxOFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-bit quantization gets the model to fit in memory, but there are a handful of other tricks we're going to need to employ in order to be able to fit the fine-tuning process in memory.\n",
        "\n",
        "I'll go over them here before we apply them down in the \"Training Arguments\" part of the code.\n",
        "\n",
        "**TODO** - I plan to move the LoRA and Paged Optimizers sections into their own separate tutorials, and provide much more condensed explanations in this Notebook!"
      ],
      "metadata": {
        "id": "gAnl-DmlxRya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. LoRA"
      ],
      "metadata": {
        "id": "Nl2hQnP7bH91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA stands for Low Rank Adaptation. It's a particular Parameter Efficient Fine-Tuning (\"peft\") technique, but it seems to be so much the default choice that maybe we don't even need a category for \"peft\" approaches anymore. 😅\n"
      ],
      "metadata": {
        "id": "jICI58cra831"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Learning Without Forgetting**\n",
        "\n",
        "The goal of fine-tuning is to modify the LLM's behavior in some way, without losing all of the incredible capabilities of the original model.\n",
        "\n",
        "> Note: I could imagine why it might be challenging to retain the original capabilities. If you try to fine-tune the LLM to predict the next word in a small dataset, why should it bother with language understanding when it could probably just memorize the contents of your dataset?! 😝\n",
        "\n",
        "One way to achieve this is to not touch the original model at all (i.e., \"freeze\" the original weights), and instead train some additional small components that we add to the model in order to \"adjust\" it's behavior.\n",
        "\n"
      ],
      "metadata": {
        "id": "fAE-5nshKrT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adapter Layers vs. LoRA**\n",
        "\n",
        "\"Adapter Layers\" were were an approach to this where we inserted additional (presumably small?) feed-forward neural networks into the model's flow.\n"
      ],
      "metadata": {
        "id": "5QKuqxx4Lx6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![Adapter Layers Illustration](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*_uWLznsq8ClxcCA57HDlXA.png)"
      ],
      "metadata": {
        "id": "eftsem4KM4LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA, on the other hand, seems a little more logical to me. Instead of _inserting_ neural networks, we add them to the side.\n",
        "\n",
        "An embedding goes through the original model component, as well as a small calculation on the side, and the result of the small calculation is added onto the result of the original component. This parallel flow is captured by the below illustration (ignore the _equations_ given for `A` and `B`--these state how those two matrices are initialized, which doesn't seem worth emphasizing!)."
      ],
      "metadata": {
        "id": "TqXtgrDuL1Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![LoRA's parallel calculation illustration](https://miro.medium.com/v2/resize:fit:1086/format:webp/1*x7xuaEJGVKvaF_F_XOtwJA.png)\n",
        "\n",
        "This illustration comes from the original LoRA paper [here](https://arxiv.org/pdf/2106.09685) (First authors are Edward Hu and Yelong Shen at Microsoft)."
      ],
      "metadata": {
        "id": "CtR2ZzSdOAZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example in this Notebook the \"rank\" `r` is set to 16, and we're using Mistral 7B which has an embedding size of 4,096.\n",
        "\n",
        "Our \"side calculation\" is to take the embedding $ x $ of $ 1 \\times 4096 $ and project it onto a matrix $ A $ of $ 4096 \\times 16 $ to get an intermediate vector that is only $ 1 \\times 16 $!\n",
        "\n",
        "Before we can add our \"adjustment\" back in, we have to project back into the embedding space by multiplying our $ 1 \\times 16 $ vector with a $ 16 \\times 4096 $ matrix $ B $.\n",
        "\n"
      ],
      "metadata": {
        "id": "OHoe4EPBOf90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What's \"Low Rank\"?**\n",
        "\n",
        "Rank is a matrix math concept. If we take $ C = AB $, then $ C $ has \"rank 16\". It's a big matrix that can actually be represented by two much smaller ones.\n",
        "\n",
        "This concept has important implications in a neural network. Here's the terminology / framing I'd prefer.\n",
        "\n",
        "Think of A and B as defining a neural network with 16 neurons in the hidden layer. Each of the 16 neurons is looking for a different pattern in the input embedding.\n",
        "\n",
        "When we take the dot product between the embedding and the weights of one of the neurons, we get a single value that reflects the similarity between the input and the pattern stored by the neuron.\n",
        "\n",
        "So $ A $ defines our hidden layer of 16 neurons, and is only capable of extracting 16 features from the input embedding (whereas $ W $ extracts 4,096!).\n",
        "\n",
        "The output of our hidden layer is just $ 1 \\times 16 $--16 neuron activations.\n",
        "\n",
        "Then, $ B $ stores 16 different possible \"adjustments\" to make to the result of $ xW $. The adjustments in B are scaled by the \"activation\" of the corresponding neuron.  \n",
        "\n",
        "For example, if neuron 0 responds strongly to the input embedding (i.e., has a high dot product), then row 0 of $ B $ will be scaled up and have a stronger impact on the result of $ xW $.\n",
        "\n"
      ],
      "metadata": {
        "id": "8pMinRH41QXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear vs. Non-Linear**\n",
        "\n",
        "One flaw in my \"neural network\" analogy, though, is that we aren't applying an activation function to $ xA $.\n",
        "\n",
        "$ xAB $ only creates a linear model that can't be as \"sophisticated\" in its behavior as a true neural network.\n",
        "\n",
        "Limiting this to a linear model may relate to minimizing how much we're able to change the model's behavior--I'm not entirely sure!\n",
        "\n",
        "But it also has another benefit that I'll explain next."
      ],
      "metadata": {
        "id": "rlSmos-W7xFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merging LoRA Weights**\n",
        "\n",
        "A nice property of linear operations like the ones here is that they can often be reduced. _Once A and B have been learned_, we can think of them as constants, and we can actually merge them into the model's weight matrices!\n",
        "\n",
        "Let's say `W` is one of the original models components, like the \"Key\" projection matrix in the attention block.\n",
        "\n",
        "If `x` is an embedding, then the original math was just `xW`.\n",
        "\n",
        "We're modifying this to `xW + xAB`. Matrix algebra works similar to regular algebra in that we can pull out that `x` to have `x(W + AB)`. Since W, A, and B are all \"constants\" at this point (because we've completed training), we can just perform the multiplcation and sum `W + AB` to get our new values for `W`.\n",
        "\n",
        "(Note: In order for the above algebra to work, the operation has to occur _before_ any activation function--i.e., `activation(xW + xAB)`, _not_ `activation(xW) + xAB`).\n",
        "\n",
        "Merging the LoRA weights back into the original model means that we aren't actually performing any additional math at inference time! The original \"adapters\" technique added in more model components that would slow down inference.\n",
        "\n",
        "It also says something kind of interesting about how LoRA works--it's not doing anything that couldn't have been accomplished by modifying the original weights directly!"
      ],
      "metadata": {
        "id": "0kraCBzjfeLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact on Training Requirements**\n",
        "\n",
        "LoRA reduces the number of trainable parameters dramatically. For example, if W is [4096 x 4096], that's 16M parameters, but if A and B are [4096 x 16] that's only 128K parameters between the two of them--a reduction of 128x!\n",
        "\n",
        "(The amount of reduction is based on the embedding size and the 'r' value used. The LoRA paper reports a reduction of 10,000x for GPT-3, which had a whopping embedding size of 12,288!)\n",
        "\n",
        "Wow! That must have an incredible impact on training speed and memory requirements, right? ...No.\n",
        "\n",
        "As I discussed in section 3, the problem is that for decent batch sizes and sequence lengths, it's the activation values that dominate the memory consumption, and not the optimizer states.  \n",
        "\n",
        "The LoRA paper touts a 3x reduction in memory consumption, but I don't think you'll see this in practice. Maybe they got this on some of the common transformer benchmarks like GLUE, which only require sequence lengths of 128 - 512 (see Table 10 of their paper).\n",
        "\n",
        "The QLoRA paper seems to corroborate this on page 3, under \"Memory Requirement of Parameter-Efficient Finetuning\", where they point out that \"most of the memory footprint for LLM finetuning comes from activation gradients and not from the learned LoRA parameters\". They point out that it doesn't cost much to apply to LoRA to more of the model components, and find they get much better results when applying LoRA to all of the weight matrices.\n",
        "\n",
        "_Optimizing `r`_\n",
        "\n",
        "I think a key take-away for this is that you probably should think of `r` less in terms of \"compression\" and \"efficiency\" and more like fine-tuning the number of neurons in your model. There's probably an ideal value that could be bigger or smaller for your application / dataset."
      ],
      "metadata": {
        "id": "oebPHvOjh9jP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reduced Deployment Cost**\n",
        "\n",
        "The primary benefit touted by the LoRA paper is different than what you'd expect. They emphasize how this approach makes it much quicker, _in a production setting_, to swap in and out models tuned for different tasks.\n",
        "\n",
        "For example, if task 1 is defined by A_1, B_1 and task 2 is defined by A_2, B_2, then you can switch from task 1 to 2 by subtracting out task 1 `W - A_1B_1` and adding in task 2 `W + A_2B_2`.\n",
        "\n",
        "Perhaps a related benefit for the rest of us is that we can pass around tuned models with less internet bandwidth. 🤷‍♂️\n"
      ],
      "metadata": {
        "id": "BbzhZPvthV25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Real Benefit?**\n",
        "\n",
        "I'm wondering if the primary reason for LoRA's popularity is simply that peft methods in general produce better fine-tuning results than fine-tuning the LLM directly.\n",
        "\n",
        "Like other peft methods, it serves as a kind of \"regularization\" to the training process that helps avoid over-fitting to the fine-tuning task.\n",
        "\n",
        "And then maybe LoRA is just the best performing peft approach? 🤷‍♂️"
      ],
      "metadata": {
        "id": "S8cMsN8Borzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling Parameter**\n",
        "\n",
        "There's a scaling parameter (that's typically ommitted from the equation), which I'll call $ s $ for the moment. The most common scaling amount is 2.\n",
        "\n",
        "The full equation is $ xW + sxAB $\n",
        "\n",
        "You could think of this as explicitly increasing (or decreasing) the influence that our LoRA weights have on the model.\n",
        "\n",
        "Scaling parameters like this are a little quirky, because the model could simply learn this same behavior in A by learning values for A that are, e.g., twice as large. (It could also learn to _contradict_ your scaling factor by learnig values for A that are half as large! 😅)\n",
        "\n",
        "I think these are introduced when the engineer believes there is some intrinsic scaling factor that should exist in order for the model to perform well, and so extracting this factor helps the model during the learning process.\n",
        "\n",
        "Here's one possible interpretation:\n",
        "\n",
        "We know that we use tiny learning rate values, like 0.00005, during training because we know that smaller adjustments to the weight values are better for convergence.\n",
        "\n",
        "If we think that $ xAB $ should have a scaled up (or down!) impact, though, then pulling out $ s $ allows for those smaller gradient updates we want while still maintaining this amplified behavior.\n",
        "\n",
        "(Other examples are the \"cfg scale\" parameter in Stable Diffusion, or the divide-by-8 step in the Transformer!)"
      ],
      "metadata": {
        "id": "Ttp8ABBOtpwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alpha**\n",
        "\n",
        "Rather than defining the scaling parameter explicitly as 2x, they introduce a parameter $ \\alpha $ (alpha) and define the scaling factor as\n",
        "\n",
        "$\n",
        "s = \\frac{\\alpha}{\\text{rank}}\n",
        "$\n",
        "\n",
        "They explain this in the [paper](https://arxiv.org/pdf/2106.09685) in section 4.1 on page 4.\n",
        "\n",
        "If I understand correctly, it relates to the hyperparameter tuning process, and the theory and methodology is:\n",
        "\n",
        "* The scaling property and learning rate are redundant.\n",
        "* If you find a good learning rate, then you can keep that value, pick a fixed value for alpha, and then play with different values of `r`.\n",
        "\n",
        "This has an interesting implication that I don't think is captured by the recommendation I've seen around of \"choose alpha to be twice r\".\n",
        "\n",
        "By fixing the value for $ \\alpha $, this implies that larger values of `r` should have $ xAB $ scaled _down_.\n",
        "\n",
        "I think this makes sense--if we go from having 16 neurons contribute adjustments to having 256 neurons contribute their adjustments, the total adjustment is going to be larger. It seems logical to me that we'd want to scale down $ xAB $ in order for it to have a similar impact as it was before.\n",
        "\n",
        "If you kept alpha fixed at 32, this would occur naturally:\n",
        "\n",
        "$\n",
        "s = \\frac{\\alpha = 32}{\\text{rank} = 16} = 2\n",
        "$\n",
        "\n",
        "$\n",
        "s = \\frac{\\alpha = 32}{\\text{rank} = 256} = \\frac{1}{8}\n",
        "$\n",
        "\n",
        "I think this may be confirmed by Sebastian's experiments [here](https://magazine.sebastianraschka.com/i/138081202/balancing-lora-hyperparameters-r-and-alpha) where he noticed that for rank = 256 he got better results with a scaling factor of 0.5 (alpha = 128).\n",
        "\n",
        "Perhaps the practice instead has been to keep $ s $ fixed at 2 and then to explore the learning rate, but I suspect the LoRA authors' methodology is the better approach!\n"
      ],
      "metadata": {
        "id": "M1q6sHD9CHKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In HuggingFace**\n",
        "\n",
        "In the StackLLaMa v1 example, they used the following settings:\n",
        "\n",
        "```python\n",
        "from peft import LoraConfig\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "```\n",
        "\n",
        "I can't speak to the choice of dropout or bias yet, or how the choice of task_type impacts things!"
      ],
      "metadata": {
        "id": "3BmUmNv_sgo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# v1 used r=16 and alpha=32,\n",
        "# We're going with the v2 settings of r=8 and alpha=16.\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "d8LnG1iyZ-bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Where to Apply LoRA**\n",
        "\n",
        "I think there may be an important omission in the StackLLaMa configuration...\n",
        "\n",
        "The suggestion from the original LoRA paper was to only apply the technique to the Query and Value projection matrices in the Attention blocks.\n",
        "\n",
        "The QLoRA authors make the point repeatedly, though, that it's \"critical\" to apply LoRA to all layers in order to match 16-bit performance.\n",
        "\n",
        "From Section 4, page 6 of the paper, [here](https://arxiv.org/pdf/2305.14314.pdf)\n",
        "\n",
        "> \"...we find that the most critical LoRA hyperparameter is how many LoRA adapters are used in total and that LoRA on all linear transformer block\n",
        "layers are required to match full finetuning performance\"\n",
        "\n",
        "And again, they argue there isn't much of a penalty to this choice, since LoRA doesn't have as much impact on memory consumption as the marketing hype implies.\n",
        "\n",
        "Their analysis is on appendix A.1., page 22."
      ],
      "metadata": {
        "id": "1luYLZodKLIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO - AB as deltaW**\n",
        "\n",
        "The LoRA authors present the purpose of AB a little differently. They show it as a substitution for the full gradient update that we would normally make.\n",
        "\n",
        "Sebastian frames it similarly [here](https://magazine.sebastianraschka.com/i/138081202/a-brief-introduction-to-lora), and that it makes sense that pre-training would require a full update, whereas tuning ought to be represented by a smaller update."
      ],
      "metadata": {
        "id": "--oHGmLYyN_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Paged Optimizers"
      ],
      "metadata": {
        "id": "vex1E1BKdbsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paging in Windows/Linux/etc.**\n",
        "\n",
        "It's not just GPUs that have problems with running out memory--our laptops have the same problem.\n",
        "\n",
        "When you try to open one too many Chrome tabs, we've all gotten that error message:\n",
        "\n",
        "```\n",
        "\"RuntimeError: Windows out of memory. Tried to allocate 572.00 MiB (23.99 GiB total capacity; 21.62 GiB already allocated; 0 bytes free; 22.67 GiB reserved in total by Windows)\n",
        "```\n",
        "\n",
        "Right? 😂\n",
        "\n",
        "No. Operating systems avoid this by using \"paging\". It's a pretty simple concept, where essentially you swap blocks of memory (\"pages\", typically 4KB each) in and out of memory as needed. The pages that aren't currently in memory are stored on your hard drive.\n",
        "\n",
        "It comes at a cost, of course--reading and writing to the hard drive is slower than memory. The OS tries to minimize the amount of page \"swapping\" that occurs, but when that Memory Utilization line graph starts flirting with 100%, your laptop starts to get sluggish.\n",
        "\n",
        "(When you start to run out of memory, this is referred to as \"Memory Pressure\". I've seen that term around and have been wondering what it mean!)\n",
        "\n",
        "I had a conversation with ChatGPT [here](https://chat.openai.com/share/9a55f350-b49e-4cc9-b47c-a05dc5276b61) about how paging works in an OS; I thought it did a good job explaining it. Though I do have a background in computer architecture and operating systems. 😊\n"
      ],
      "metadata": {
        "id": "-NjguaQPdg8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NVIDIA Unified Memory**\n",
        "\n",
        "Your laptop's OS handles paging between memory and drive in the background. Can you imagine what a pain it would be if programmers had to implement \"paging\" themselves in every application?!\n",
        "\n",
        "Well, that's what it's been like for GPU programmers! You could move stuff in and out of GPU memory to avoid running out of space, but you had to manage this yourself.\n",
        "\n",
        "So NVIDIA created its \"Unified Memory\" feature to provide a similar service to GPU programmers, handling swapping in the background.\n",
        "\n",
        "Again, marketing hype might lead you to think that \"Unified Memory\" means both memory types can be used with no or negligible performance degradation, but that's not what it is. The point is really to \"improve programmer productivity\" ([here](https://developer.nvidia.com/blog/simplifying-gpu-application-development-with-heterogeneous-memory-management/)).\n",
        "\n",
        "It's still pretty damn cool, though... I assumed the QLoRA team implemented page-swapping themselves and this would be a whole topic to research and explain. Nope! They just used the Unified Memory feature to allocate the memory for the optimizer states, and the swapping is handled by CUDA.\n",
        "\n",
        "(Their \"Paged Optimizer\" section on page 5 of the [paper](https://arxiv.org/pdf/2305.14314.pdf) is a single short paragraph. 😆)\n",
        "\n"
      ],
      "metadata": {
        "id": "iueW4rFx2o3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus - Why GPU access of CPU Memory is slow**\n",
        "\n",
        "https://chat.openai.com/share/b536522b-cb2c-4120-904e-89bcc9cd4b88\n",
        "\n",
        "* The implementation of GPU memory (GDDR) is different from CPU memory (DDR).\n",
        "* GPU memory is designed to allow fast access to large blocks of data, so it has **higher bandwidth**.\n",
        "* CPU memory has lower **latency**."
      ],
      "metadata": {
        "id": "jo60GR23npi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3. Additional Techniques"
      ],
      "metadata": {
        "id": "vOmlpCrKxcLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Checkpointing**\n",
        "\n",
        "* Deletes and re-calculates some intermediate values to lower the peak memory.\n",
        "    * Careful--you'll take the performance hit whether you need it or not!\n",
        "* Use it allow for longer sequence lengths, but batch accumulation seems to be the better approach for enabling larger batches.\n",
        "\n",
        "**Batch Accumulation**\n",
        "\n",
        "* To get a larger effective batch size, run multiple steps at a smaller size and accumulate the gradients before applying the update.\n",
        "* Mathematically the same.\n",
        "* Only downside is you potentially miss out on parallelism in the GPU. (i.e., doubling the batch size often takes less than twice as long).\n",
        "* It's better to use GA than to try to use larger BS with GC.\n",
        "\n",
        "**8-bit Optimizers**\n",
        "\n",
        "* Doesn't seem to improve things at longer sequence lengths.\n",
        "\n",
        "**Attention Implementation**\n",
        "\n",
        "* 'sdpa' is the default. 'flash_attn_2' is the original and does seem to be a little different, but I think you can ignore it.\n",
        "* SDPA makes a big difference for longer sequence lengths.\n",
        "   * You can't do BS 2 and SL 1,024 on the A100 without it.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IdTUVZ-LxcLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S6. Training Setup"
      ],
      "metadata": {
        "id": "HyuzJcjZBWAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1. Training Arguments"
      ],
      "metadata": {
        "id": "gs8IFbI5PzTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter Choices**\n",
        "\n",
        "(Copied from the introduction)\n",
        "\n",
        "| Settings                    | Version 1       | Version 2       |\n",
        "|-----------------------------|-----------------|-----------------|\n",
        "| Model                       | LLaMA 1 7B      | LLaMA 2 7B      |\n",
        "| Maximum Sequence Length     | 1024            | None            |\n",
        "| Effective Batch Size        | 4               | 8               |\n",
        "| Batch Size, Accumulation Steps | 4, 1         | 4, 2            |\n",
        "| Learning Rate               | 1e-5            | 1e-4            |\n",
        "| Steps                       | 5000            | 500             |\n",
        "| Optimizer                   | -               | paged_adamw_32bit |\n",
        "| Gradient Checkpointing      | False           | False           |\n",
        "| Lora ‘r’ and ‘alpha’        | r=16, alpha=32  | r=8, alpha=16   |\n",
        "| Quantization                | 8-bit           | 4-bit           |\n",
        "| BFloat16                    | False           | True            |\n",
        "\n",
        "A couple parameter choices aren't specified, and so must be using the default values. The documentation is hard to follow, but as best I can tell the default optimizer for the Trainer is AdamW, and setting the sequence length to 'None' causes it to retrieve that value from the tokenizer.\n"
      ],
      "metadata": {
        "id": "QGFbuusyABX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "    # Batch Size\n",
        "    # They used a batch size of 4, and no gradient accumulation (i.e., \"1\")\n",
        "    per_device_train_batch_size = 1,  # Batch size during training\n",
        "\n",
        "    gradient_accumulation_steps = 4,  # Accumulating across multiple batches\n",
        "                                      # allows you to use a smaller batch size,\n",
        "                                      # but still simulate a larger one.\n",
        "\n",
        "    # Training Steps\n",
        "    max_steps = 500,  # Number of steps to train for.\n",
        "    save_steps = 100,  # Number of steps between model checkpoints\n",
        "\n",
        "    # Optimization Settings\n",
        "    learning_rate = 1e-4,  # Learning rate\n",
        "    lr_scheduler_type = \"cosine\",  # Type of learning rate scheduler\n",
        "    warmup_steps = 100,  # Number of warmup steps for the learning rate scheduler\n",
        "    weight_decay = 0.05,  # Weight decay (related to regularization)\n",
        "\n",
        "    # Memory Conservation / Precision\n",
        "    gradient_checkpointing = True,  # Gradient checkpointing uses less memory\n",
        "                                     # at the cost of speed. Does not impact\n",
        "                                     # quality.\n",
        "\n",
        "    # If T4:\n",
        "    fp16 = True,  # 16-bit precision\n",
        "\n",
        "    # If A100 or L4:\n",
        "    #bf16 = True,  # 16-bit precision using \"Brain Float\" bfloat16 datatype.\n",
        "\n",
        "    # Distributed Training Settings\n",
        "    ddp_find_unused_parameters = False,  # DDP = Distributed Data Parallel\n",
        "\n",
        "    # Evaluation Settings\n",
        "    per_device_eval_batch_size = 1,  # Batch size during evaluation\n",
        "    evaluation_strategy = \"steps\",  # Evaluation strategy during training (\"steps\" or \"epoch\")\n",
        "    eval_steps = 100,  # Number of steps between evaluations\n",
        "\n",
        "    # Dataloader Settings\n",
        "    dataloader_drop_last = True,  # Drop the last batch if it's smaller than the\n",
        "                                  # specified batch size\n",
        "\n",
        "    # Choice of optimizer\n",
        "    optim = 'paged_adamw_32bit',\n",
        "    #optim = 'paged_adamw_8bit',\n",
        "    #optim = 'adamw_torch',   # I believe this is the default.\n",
        "\n",
        "    # Output Directory\n",
        "    output_dir = \"./llama-se\",  # Directory to save the model and checkpoints\n",
        "                                # \"se\" is short for Stack Exchange.\n",
        "\n",
        "    # Logging and Reporting\n",
        "    logging_steps = 1,  # Number of steps before logging\n",
        "    report_to = \"wandb\",  # Reporting to Weights & Biases (wandb)\n",
        "    run_name = \"mistral-7b-finetuned\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Vm1uNDplW9QZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import logging, set_seed\n",
        "\n",
        "set_seed(args.seed)\n",
        "\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "9qfndlyZIPT8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2. SFTTrainer"
      ],
      "metadata": {
        "id": "lrZw7yAcP74i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The `trl` library defines this Supervised Fine-Tuning Trainer `SFTTrainer` that's going to do a number of steps for us.\n",
        "\n",
        "* Docs for SFTTrainer: https://huggingface.co/docs/trl/sft_trainer\n",
        "    * They call it a light wrapper for the `Trainer` class in `transformers`.\n"
      ],
      "metadata": {
        "id": "0r3sEvSW6E-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "\n",
        "    model = model,\n",
        "\n",
        "    args = training_args,\n",
        "\n",
        "    # This wasn't in the original example, but a warning suggested that this\n",
        "    # will default to 1,024 if I don't set it.\n",
        "    max_seq_length = args.seq_length,\n",
        "\n",
        "    train_dataset = train_dataset,\n",
        "\n",
        "    eval_dataset = valid_dataset,\n",
        "\n",
        "    peft_config = lora_config,\n",
        "\n",
        "    packing = True,\n",
        ")\n",
        "\n",
        "print(\"Building SFTTrainer (and building LoRA?) took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "Qx0uyYNcP6_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f87d055-b86a-4331-ad79-e866716d06c9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building SFTTrainer (and building LoRA?) took: 0:00:01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:342: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3. Impact of LoRA"
      ],
      "metadata": {
        "id": "tKCUdJ3z4csc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying LoRA modifies the architecture of our model, so it's interesting to take a peek at the details.\n",
        "\n",
        "**TODO** - I'm thinking to move the outputs up to the LoRA section, and the code for them down into the Appendix.\n"
      ],
      "metadata": {
        "id": "labMqkVO8r1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original example includes a different version of the following printout that was broken.\n",
        "\n",
        "The problem is that you can no longer use `param.numel()` reliably, since any matrices which have been quantized (some are, some arent'!) will now report has having **half** as many elements as they actually do.\n",
        "\n",
        "I've circumevented this with a little hack explained in the code.\n",
        "\n"
      ],
      "metadata": {
        "id": "THa15gOu44X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = 0\n",
        "\n",
        "all_params = 0\n",
        "\n",
        "# For all of the named parameters\n",
        "for _, param in trainer.model.named_parameters():\n",
        "\n",
        "    # Tally all parameters in the model, trainable or not.\n",
        "    # Note - This step will not count quantized parameters correctly!\n",
        "    #all_params += param.numel()\n",
        "\n",
        "    # Below is a hacky way of solving it, but should work in this situation.\n",
        "    #\n",
        "    # Quantized matrices get unrolled. They have a two dimensional size still,\n",
        "    # but the second dimension is 1.\n",
        "    # So, if it's two dimensional, and the second dimension is length 1, then\n",
        "    # let's assume it's been quantized.\n",
        "    if len(param.size()) == 2 and param.size()[1] == 1:\n",
        "\n",
        "        # Double the parameter count to adjust for 4-bit quantization.\n",
        "        all_params += param.numel() * 2\n",
        "\n",
        "        # No quantized matrices should be trainable.\n",
        "        assert not param.requires_grad\n",
        "\n",
        "    # Otherwise, assume it's not quantized\n",
        "    else:\n",
        "        # Add the number of elements to the tally.\n",
        "        all_params += param.numel()\n",
        "\n",
        "        # Tally the parameters that will be fine-tuned.\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "\n",
        "print(\"How much did we reduce the training burden by?\\n\")\n",
        "print(\"      Total parameters: {:,}\".format(all_params))\n",
        "print(\"  Trainable parameters: {:,}\".format(trainable_params))\n",
        "print(\"  Percentage trainable: {:.2}%\".format(100 * trainable_params / all_params))"
      ],
      "metadata": {
        "id": "CzL_oD9U8sMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcb75d1-8833-4762-c6f8-c31130c44a72"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How much did we reduce the training burden by?\n",
            "\n",
            "      Total parameters: 7,245,139,968\n",
            "  Trainable parameters: 3,407,872\n",
            "  Percentage trainable: 0.047%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How's memory usage looking now?\n",
        "\n",
        "This is higher than what we saw prior to LoRA. LoRA actually adds parameters to the model, so it makes sense that it would increase the size!"
      ],
      "metadata": {
        "id": "QkZWg54bTwo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_gpu_mem()"
      ],
      "metadata": {
        "id": "hGR5Tc4LTom-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "5b7cd9eb-defa-4991-8b2b-009db1ac57d1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0 memory.total [MiB]  memory.used [MiB]\n",
              "1          15360 MiB           6367 MiB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc438afd-e013-4e66-aaf7-6035d98a62dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>memory.total [MiB]</th>\n",
              "      <th>memory.used [MiB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15360 MiB</td>\n",
              "      <td>6367 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc438afd-e013-4e66-aaf7-6035d98a62dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc438afd-e013-4e66-aaf7-6035d98a62dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc438afd-e013-4e66-aaf7-6035d98a62dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"check_gpu_mem()\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"memory.total [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"15360 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" memory.used [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" 6367 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model architecture has changed, let's check it out..."
      ],
      "metadata": {
        "id": "Rq00oivo_cOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model"
      ],
      "metadata": {
        "id": "9sjrXK5I_ej7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbb6b6d-cef0-42b8-a34d-e9514e336a18"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): MistralForCausalLM(\n",
              "      (model): MistralModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x MistralDecoderLayer(\n",
              "            (self_attn): MistralSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (rotary_emb): MistralRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): MistralMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): MistralRMSNorm()\n",
              "            (post_attention_layernorm): MistralRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): MistralRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print out the parameter names and sizes for a couple layers of the model.\n",
        "\n",
        "We'll see the impact of the 4-bit quantization--the matrices have been \"unrolled\", and every byte now holds two 4-bit values. (If you tally up the parameter counts now, you'll only get ~3.5B instead of 7B!)."
      ],
      "metadata": {
        "id": "fffi9RvvRq6o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwrh9T74RrHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de48f13-29de-4b77-c5bd-cfe2593d7d36"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(trainer.model.named_parameters())\n",
        "\n",
        "print('The model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print(\"Parameter Name                                              Dimensions       Total Values    Trainable\\n\")\n",
        "#print(\"{:<55} {:>16}    {:>6}    {:}\".format(\"Parameter Name\", \"Dimensions\", \"Total Values\", \"Trainable\"))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p_name, p in params[0:1]:\n",
        "\n",
        "    p_name = p_name[17:]\n",
        "\n",
        "    if len(p.size()) == 1:\n",
        "        p_dims = \"{:>10,} x {:<10}\".format(p.size()[0], \"-\")\n",
        "    if len(p.size()) == 2:\n",
        "        p_dims = \"{:>10,} x {:<10,}\".format(p.size()[0], p.size()[1])\n",
        "\n",
        "    print(\"{:<55} {:}    {:>6}    {:}\".format(p_name, p_dims, format_size(p.numel()), p.requires_grad))\n",
        "\n",
        "print('\\n==== First Decoder ====\\n')\n",
        "\n",
        "for p_name, p in params[1:14]:\n",
        "\n",
        "    p_name = p_name[17:]\n",
        "\n",
        "    if len(p.size()) == 1:\n",
        "        p_dims = \"{:>10,} x {:<10}\".format(p.size()[0], \"-\")\n",
        "    if len(p.size()) == 2:\n",
        "        p_dims = \"{:>10,} x {:<10,}\".format(p.size()[0], p.size()[1])\n",
        "\n",
        "    print(\"{:<55} {:}    {:>6}    {:}\".format(p_name, p_dims, format_size(p.numel()), p.requires_grad))\n",
        "    #print(\"{:<55} {:}    {:>6}    {:}\".format(p_name, p_dims, str(p.numel()), p.requires_grad))\n",
        "\n",
        "\n",
        "print('\\n==== Second Decoder ====\\n')\n",
        "\n",
        "for p_name, p in params[14:27]:\n",
        "\n",
        "    p_name = p_name[17:]\n",
        "\n",
        "    if len(p.size()) == 1:\n",
        "        p_dims = \"{:>10,} x {:<10}\".format(p.size()[0], \"-\")\n",
        "    if len(p.size()) == 2:\n",
        "        p_dims = \"{:>10,} x {:<10,}\".format(p.size()[0], p.size()[1])\n",
        "\n",
        "    print(\"{:<55} {:}    {:>6}    {:}\".format(p_name, p_dims, format_size(p.numel()), p.requires_grad))\n",
        "\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p_name, p in params[-2:]:\n",
        "\n",
        "    if len(p.size()) == 1:\n",
        "        p_dims = \"{:>10,} x {:<10}\".format(p.size()[0], \"-\")\n",
        "    if len(p.size()) == 2:\n",
        "        p_dims = \"{:>10,} x {:<10,}\".format(p.size()[0], p.size()[1])\n",
        "\n",
        "    print(\"{:<55} {:}    {:>6}    {:}\".format(p_name, p_dims, format_size(p.numel()), p.requires_grad))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 419 different named parameters.\n",
            "\n",
            "Parameter Name                                              Dimensions       Total Values    Trainable\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "model.embed_tokens.weight                                   32,000 x 4,096           125M    False\n",
            "\n",
            "==== First Decoder ====\n",
            "\n",
            "model.layers.0.self_attn.q_proj.base_layer.weight        8,388,608 x 1                 8M    False\n",
            "model.layers.0.self_attn.q_proj.lora_A.default.weight            8 x 4,096            32K    True\n",
            "model.layers.0.self_attn.q_proj.lora_B.default.weight        4,096 x 8                32K    True\n",
            "model.layers.0.self_attn.k_proj.weight                   2,097,152 x 1                 2M    False\n",
            "model.layers.0.self_attn.v_proj.base_layer.weight        2,097,152 x 1                 2M    False\n",
            "model.layers.0.self_attn.v_proj.lora_A.default.weight            8 x 4,096            32K    True\n",
            "model.layers.0.self_attn.v_proj.lora_B.default.weight        1,024 x 8                 8K    True\n",
            "model.layers.0.self_attn.o_proj.weight                   8,388,608 x 1                 8M    False\n",
            "model.layers.0.mlp.gate_proj.weight                     29,360,128 x 1                28M    False\n",
            "model.layers.0.mlp.up_proj.weight                       29,360,128 x 1                28M    False\n",
            "model.layers.0.mlp.down_proj.weight                     29,360,128 x 1                28M    False\n",
            "model.layers.0.input_layernorm.weight                        4,096 x -                 4K    False\n",
            "model.layers.0.post_attention_layernorm.weight               4,096 x -                 4K    False\n",
            "\n",
            "==== Second Decoder ====\n",
            "\n",
            "model.layers.1.self_attn.q_proj.base_layer.weight        8,388,608 x 1                 8M    False\n",
            "model.layers.1.self_attn.q_proj.lora_A.default.weight            8 x 4,096            32K    True\n",
            "model.layers.1.self_attn.q_proj.lora_B.default.weight        4,096 x 8                32K    True\n",
            "model.layers.1.self_attn.k_proj.weight                   2,097,152 x 1                 2M    False\n",
            "model.layers.1.self_attn.v_proj.base_layer.weight        2,097,152 x 1                 2M    False\n",
            "model.layers.1.self_attn.v_proj.lora_A.default.weight            8 x 4,096            32K    True\n",
            "model.layers.1.self_attn.v_proj.lora_B.default.weight        1,024 x 8                 8K    True\n",
            "model.layers.1.self_attn.o_proj.weight                   8,388,608 x 1                 8M    False\n",
            "model.layers.1.mlp.gate_proj.weight                     29,360,128 x 1                28M    False\n",
            "model.layers.1.mlp.up_proj.weight                       29,360,128 x 1                28M    False\n",
            "model.layers.1.mlp.down_proj.weight                     29,360,128 x 1                28M    False\n",
            "model.layers.1.input_layernorm.weight                        4,096 x -                 4K    False\n",
            "model.layers.1.post_attention_layernorm.weight               4,096 x -                 4K    False\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "base_model.model.model.norm.weight                           4,096 x -                 4K    False\n",
            "base_model.model.lm_head.weight                             32,000 x 4,096           125M    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the output directory now, before training, in case it doesn't work or something. 😝"
      ],
      "metadata": {
        "id": "s9sufYh6_gv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create the output directory where we'll save the final checkpoint.\n",
        "\n",
        "\n",
        "os.makedirs(training_args.output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "6xEjStTMOT5w"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S7. Training Loop"
      ],
      "metadata": {
        "id": "KJjOXnyn838T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO** - Turn off wandb logging, or show how to set up the secrets functionality."
      ],
      "metadata": {
        "id": "SYmz9Zok_T_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "wandb_key = userdata.get('wandb_api_key')\n",
        "\n",
        "wandb.login(key = wandb_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orf2IfWLSzyg",
        "outputId": "37637c8f-fddc-437f-a68b-0649b6087d0a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrismccormick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training...\")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "lZpPuiUYQCLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "92d7e889-73d2-41b8-ff77-40ff78968e3b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240425_211757-t7n4swvh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/chrismccormick/huggingface/runs/t7n4swvh' target=\"_blank\">mistral-7b-finetuned</a></strong> to <a href='https://wandb.ai/chrismccormick/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/chrismccormick/huggingface' target=\"_blank\">https://wandb.ai/chrismccormick/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/chrismccormick/huggingface/runs/t7n4swvh' target=\"_blank\">https://wandb.ai/chrismccormick/huggingface/runs/t7n4swvh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='249' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [249/500 1:04:06 < 1:05:08, 0.06 it/s, Epoch 0.50/9223372036854775807]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.298900</td>\n",
              "      <td>1.020498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.376900</td>\n",
              "      <td>1.012128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 2:10:28, Epoch 1/9223372036854775807]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.298900</td>\n",
              "      <td>1.020498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.376900</td>\n",
              "      <td>1.012128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.504000</td>\n",
              "      <td>1.009438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.581500</td>\n",
              "      <td>1.008276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.156300</td>\n",
              "      <td>1.007963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=1.4079855926036835, metrics={'train_runtime': 7844.6501, 'train_samples_per_second': 0.255, 'train_steps_per_second': 0.064, 'total_flos': 8.7417667190784e+16, 'train_loss': 1.4079855926036835, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1. Save the Trained Model"
      ],
      "metadata": {
        "id": "-gMxMDYEB4ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's"
      ],
      "metadata": {
        "id": "EQ2vR9eUm-wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# StackLLaMA version 1 didn't have this step--it's different than saving\n",
        "# the final checkpoint.\n",
        "trainer.save_model(training_args.output_dir)\n",
        "\n",
        "print(\"Saving last checkpoint of the model\")\n",
        "\n",
        "# Create a subdirectory for the checkpoint.\n",
        "output_dir = os.path.join(training_args.output_dir, \"final_checkpoint\")\n",
        "\n",
        "# Call `save_pretrained`, which I'm guessing allows for the use of\n",
        "# `from_pretrained`?\n",
        "trainer.model.save_pretrained(output_dir)\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    args = get_args()\n",
        "#    assert args.model_path != \"\", \"Please provide the llama model path\"\n",
        "\n"
      ],
      "metadata": {
        "id": "70UnYuMFQGPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a08da99-8f3f-42b3-d43a-e7622b3ec3f6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving last checkpoint of the model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what the directory structure looks like:"
      ],
      "metadata": {
        "id": "fl7uLW-qnLwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "lLeDearonPTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that it _only saves the adapter weights_, and not the full model! That `adapter_model.safetensors` file is only about 13MB."
      ],
      "metadata": {
        "id": "u-C1TZn9nQX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2. Performance After Training"
      ],
      "metadata": {
        "id": "tCyBPYMw82-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same code as the \"Performance Before Tuning\" section, just make sure to now call `trainer.model`."
      ],
      "metadata": {
        "id": "KTGuDpuI85TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Earlier in the Notebook, we selected a specific example to look at and play\n",
        "# with.\n",
        "example = plucked_example\n",
        "\n",
        "text = f\"Question: {example['question']}\\n\\nAnswer: \"\n",
        "\n",
        "#Desired answer: {example['response_j']}"
      ],
      "metadata": {
        "id": "t2_ZUnJd9Ae5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vFVIddl9Ae5"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\"\n",
        "\n",
        "# Tokenize the text, which returns it as a list of token ids.\n",
        "input_ids = tokenizer(\n",
        "    text,\n",
        "    return_tensors = \"pt\" # Return them in a Pytorch Tensor.\n",
        ")\n",
        "\n",
        "# Move them to the GPU.\n",
        "input_ids = input_ids.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed it in and generate output!\n",
        "outputs = trainer.model.generate(**input_ids, max_new_tokens=512)\n",
        "\n",
        "#input_ids[0].ids"
      ],
      "metadata": {
        "id": "axeFXagw9Ae5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "mVmtBzyL9Ae6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3. Merge LoRA Weights"
      ],
      "metadata": {
        "id": "d3iHzrTpCFWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematics of LoRA allow us to fold in the adapter layers.\n",
        "\n",
        "**TODO** - Copy in the equation.\n",
        "\n",
        "_However_, I suspect that the fact that the model does not fit into GPU memory without quantization means that this needs to be handled in some special way..."
      ],
      "metadata": {
        "id": "Sp_tZDm-CHp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, free up the GPU's memory!\n",
        "\n",
        "**TODO** - Haven't figured this out yet--the original code just called `empty_cache`, but that didn't work for me."
      ],
      "metadata": {
        "id": "0D453hw6DHPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Free memory for merging weights\n",
        "del model\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pvGyawFCX31",
        "outputId": "7c288eda-8dd9-42c8-a947-69b934fa674f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Did it work?\n",
        "check_gpu_mem()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "vCyKi5-kDJ67",
        "outputId": "fbab871c-5b59-4309-a3bf-89237577653a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0 memory.total [MiB]  memory.used [MiB]\n",
              "1          15360 MiB           5741 MiB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d39215c-10fa-4f84-b1a7-40eb67027b82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>memory.total [MiB]</th>\n",
              "      <th>memory.used [MiB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15360 MiB</td>\n",
              "      <td>5741 MiB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d39215c-10fa-4f84-b1a7-40eb67027b82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d39215c-10fa-4f84-b1a7-40eb67027b82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d39215c-10fa-4f84-b1a7-40eb67027b82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"check_gpu_mem()\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"memory.total [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"15360 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" memory.used [MiB]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" 5741 MiB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model again, this time using a different class with \"Peft\" in the name."
      ],
      "metadata": {
        "id": "8MivBToBDS04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "# Load again\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    # Load from the 'final_checkpoint' directory.\n",
        "    output_dir,\n",
        "\n",
        "    device_map=\"auto\",\n",
        "\n",
        "    torch_dtype=torch.float16)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "f6ec086957ff45328eb686076e47d5cc",
            "6d4f8ae68bc8476b8dfdf4b83a45ac23",
            "70cbb82869d44dc58b0123a61cb960dd",
            "01fbfc1edf8445d0a7851e8a419b565e",
            "8f79322547da4490af31b2ba72852a68",
            "f1ed83db162e4ccd8f4b863177cc126b",
            "57e5ed7f2d394e4fb27dbf65cfb50c1a",
            "bea2f81b0ab94b6cae640d2906282a5e",
            "1b86e70084864e228deb57e6c6ef3a7f",
            "6b1593c4f3b844c2a4bbb74a5d000386",
            "eaae97d658974500a5d6df0e4578ac34"
          ]
        },
        "id": "pWT_D4wsCdlx",
        "outputId": "65cadcfd-b54f-4196-b0b4-ecd66e43453f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6ec086957ff45328eb686076e47d5cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 503324160 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform the merge step.\n",
        "\n",
        "**TODO** - More on this."
      ],
      "metadata": {
        "id": "iuyakIiiDmHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = model.merge_and_unload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ejHIdO1bDkpX",
        "outputId": "1103ea68-b2d6-478a-cebc-9e5cb4cca405"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 91.06 MiB is free. Process 325788 has 14.66 GiB memory in use. Of the allocated memory 14.17 GiB is allocated by PyTorch, and 361.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-25726a453e58>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_and_unload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36mmerge_and_unload\u001b[0;34m(self, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \"\"\"\n\u001b[0;32m--> 784\u001b[0;31m         return self._unload_and_optionally_merge(\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0mprogressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogressbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_merge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_merge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madapter_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m_unload_and_optionally_merge\u001b[0;34m(self, merge, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0monload_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"base_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36monload_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_hf_hook\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlignDevicesHook\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0moffloaded_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtied_pointers_to_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 set_module_tensor_to_device(\n\u001b[0m\u001b[1;32m    348\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 91.06 MiB is free. Process 325788 has 14.66 GiB memory in use. Of the allocated memory 14.17 GiB is allocated by PyTorch, and 361.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save out the merged version."
      ],
      "metadata": {
        "id": "-lfa341VDrmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_merged_dir = os.path.join(training_args.output_dir, \"final_merged_checkpoint\")\n",
        "\n",
        "model.save_pretrained(output_merged_dir, safe_serialization=True)"
      ],
      "metadata": {
        "id": "dRgt38P5Dlia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO** - Probably want some code here to save the checkpoint in a more permanent way, like copying to gdrive?"
      ],
      "metadata": {
        "id": "bl0y53GY9SWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ▂▂▂▂▂▂▂▂▂▂▂▂▂▂"
      ],
      "metadata": {
        "id": "unupmeUxVGAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "zFN_HCF0pjAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.1. Comparing Performance\n"
      ],
      "metadata": {
        "id": "jlj2gAF__CvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i. Looking For Interesting Examples"
      ],
      "metadata": {
        "id": "awtEcFUEP_mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plucked Example**\n",
        "\n",
        "This code prints out the example at a specific index."
      ],
      "metadata": {
        "id": "IW4vJ4IJtFKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "# Loop through the training examples to reach our desired index.\n",
        "for (i, example) in enumerate(dataset):\n",
        "\n",
        "    if i == 3172:\n",
        "        #if 'salt' in example['question']:\n",
        "        print('▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂')\n",
        "        print('\\n======== Example {:,} ========\\n'.format(i))\n",
        "        print('\\n======== Question ========\\n')\n",
        "        print(wrapper.fill(example['question']))\n",
        "\n",
        "        print('\\n======== Answer ========\\n')\n",
        "        print(wrapper.fill(example['response_j']))\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "    if i > 20000:\n",
        "        print('Went through 20000!')\n",
        "        break"
      ],
      "metadata": {
        "id": "pQygOoEAQBEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Short Examples**\n",
        "\n"
      ],
      "metadata": {
        "id": "wRj5Zmc4tS22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code looks for a number of examples with fewer than (e.g., 256) tokens."
      ],
      "metadata": {
        "id": "JsAggmfRtVds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "found = 0\n",
        "\n",
        "# Loop through the training examples to reach our desired index.\n",
        "for (i, example) in enumerate(dataset):\n",
        "\n",
        "    # Prepare a training sample by combining the question and answer with some\n",
        "    # formatting.\n",
        "    text = prepare_sample_text(example)\n",
        "\n",
        "    # Tokenize and get the number of tokens.\n",
        "    ex_num_tokens = len(tokenizer(text).tokens())\n",
        "\n",
        "    if i < 155:\n",
        "        continue\n",
        "\n",
        "    if ex_num_tokens < 256 and 'python' in example['question']:\n",
        "\n",
        "        print('▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂')\n",
        "        print('\\n======== Example {:,} ========\\n'.format(i))\n",
        "        print('qid:', example['qid'])\n",
        "        print('\\n======== Question ========\\n')\n",
        "        print(wrapper.fill(example['question']))\n",
        "\n",
        "        print('\\n======== Answer ========\\n')\n",
        "        print(wrapper.fill(example['response_j']))\n",
        "\n",
        "        found = found + 1\n",
        "\n",
        "\n",
        "    if found == 5:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XhYo-OH0Wirg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbTIrtlytAIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii. Raw Mistral 7B"
      ],
      "metadata": {
        "id": "O-WNhMHks0gI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - This section will be to highlight some example generations prior to fine-tuning."
      ],
      "metadata": {
        "id": "bJ8ESV2or0sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii. HuggingFace Final Model"
      ],
      "metadata": {
        "id": "yPX_MC8au9SI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try out their fully-trained model with the interface a little ways down in this blog post:\n",
        "\n",
        "https://huggingface.co/blog/stackllama\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "StackLLaMa 1: https://huggingface.co/trl-lib/llama-7b-se-peft\n",
        "\n",
        "* Sta-La-1 only has the adapter weights.\n",
        "\n",
        "StackLLaMa 2: kashif/stack-llama-2\n",
        "\n",
        "* Sta-La-2 has the entire model.\n"
      ],
      "metadata": {
        "id": "OxLwOXT5yNEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load & Inspect"
      ],
      "metadata": {
        "id": "5-jK7sUPXL15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out memory useage prior to loading.\n",
        "check_gpu_mem()"
      ],
      "metadata": {
        "id": "IOPsJSgQXL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I copied the quantization configuration below from a huggingface tutorial Notebook [here](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf#scrollTo=HIxDplbNR_CY).\n",
        "\n",
        "> \"Let's load the model with NF4 quantization type for better results, `bfloat16` compute dtype as well as nested quantization for a more memory efficient model loading.\""
      ],
      "metadata": {
        "id": "9BCFj_bxXL2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('kashif/stack-llama-2', trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n"
      ],
      "metadata": {
        "id": "TO7UmiN2m8cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# This is what it was trained with...\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    #bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "\n",
        "    #bnb_4bit_compute_dtype = torch.bfloat16\n",
        "\n",
        "    # If T4:\n",
        "    bnb_4bit_compute_dtype = torch.float16\n",
        ")\n"
      ],
      "metadata": {
        "id": "KhiIHjs9XL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "#from transformers import MistralForCausalLM\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "\n",
        "    #model = MistralForCausalLM.from_pretrained(\n",
        "\n",
        "    # This is the completed model from the huggingface example.\n",
        "    'kashif/stack-llama-2',\n",
        "\n",
        "    quantization_config = bnb_config,\n",
        "\n",
        "    #attn_implementation = \"flash_attention_2\", # You can't use this unless\n",
        "    # you're running an A100 or newer.\n",
        "\n",
        "    torch_dtype = torch.float16,\n",
        "\n",
        "    # I was getting this output message:\n",
        "    #    \"`low_cpu_mem_usage` was None, now set to True since model is\n",
        "    #      quantized.\"\n",
        "    # If I tried setting it to False, then the Notebook crashed with:\n",
        "    #    \"Your session crashed after using all available RAM.\"\n",
        "    low_cpu_mem_usage = True,\n",
        "\n",
        ")\n",
        "\n",
        "print(\"\\nDownloading / loading model took\", format_time(time.time() - t0))\n"
      ],
      "metadata": {
        "id": "J2bZsTCbXL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm always curious what the actual class name is... 😊"
      ],
      "metadata": {
        "id": "SanygpemXL2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))"
      ],
      "metadata": {
        "id": "PztGSjnPXL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And now memory usage after loading.\n",
        "check_gpu_mem()"
      ],
      "metadata": {
        "id": "UNjCYCdUXL2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "-V0kKCbpXL2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference"
      ],
      "metadata": {
        "id": "FcZLsLncXL2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They have a demo in the blog post with configurable generation settings:\n",
        "https://huggingface.co/blog/stackllama\n",
        "\n"
      ],
      "metadata": {
        "id": "8Imsf2kXi_Ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "yf5BcZZ6jD_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generat\n",
        "```"
      ],
      "metadata": {
        "id": "FUpiJ7I8nez-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define the number of examples to sample\n",
        "num_samples = 4\n",
        "\n",
        "# Specify the GPU as our device (need to move our inputs there).\n",
        "device = \"cuda:0\"\n",
        "\n",
        "# Iterate over the random indices and print the corresponding examples\n",
        "s_i = 0\n",
        "\n",
        "for example in dataset:\n",
        "\n",
        "    s_i = s_i + 1\n",
        "\n",
        "    if not s_i % 10 == 0:\n",
        "        continue\n",
        "\n",
        "    if s_i > 40:\n",
        "        break\n",
        "\n",
        "    print('\\n\\n==== Example {:,} ====\\n\\n'.format(s_i))\n",
        "\n",
        "    # Format our prompt for the model.\n",
        "    text = f\"Question: {example['question']}\\n\\nAnswer: \"\n",
        "\n",
        "\n",
        "    # The desired answer is example['response_j']\n",
        "\n",
        "    text = \"I've heard that we haven't yet reconciled the theories of general relativity and quantum mechanics. Where do they disagree?\"\n",
        "\n",
        "    text = f\"Question: {text}\\n\\nAnswer: \"\n",
        "\n",
        "    # Tokenize the text, which returns it as a list of token ids.\n",
        "    input_ids = tokenizer(\n",
        "        text,\n",
        "        return_tensors = \"pt\" # Return them in a Pytorch Tensor.\n",
        "    )\n",
        "\n",
        "    # Move them to the GPU.\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    # Feed it in and generate output!\n",
        "    # top_p - the default for the model is 0.6, so I'm changing.\n",
        "    #outputs = model.generate(**input_ids, max_new_tokens=512, top_p = 0.9, repetition_penalty = 1.2)\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    outputs = model.generate(**input_ids,\n",
        "                             max_length=512,\n",
        "\n",
        "                             # The settings only are relevant if do_sample is true.\n",
        "                             do_sample = True,\n",
        "                             temperature = 0.9\n",
        "                             top_p = 0.9,\n",
        "                             repetition_penalty = 1.2)\n",
        "\n",
        "\n",
        "    print('\\n\\n==== Output ====\\n\\n')\n",
        "\n",
        "    # Print out the output!\n",
        "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "    print(\"Generation took:\", format_time(time.time() - t0))\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "s6HftmpqYdHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ▂▂▂▂▂▂▂▂▂▂▂▂▂▂"
      ],
      "metadata": {
        "id": "zaQ2_1FAWeE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End"
      ],
      "metadata": {
        "id": "h0-O8F-uphyZ"
      }
    }
  ]
}